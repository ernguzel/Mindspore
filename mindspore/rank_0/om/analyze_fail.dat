# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
# 2.You can search the last `------------------------>` to the node which is inferred failed.
# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.dat to get more instructions.
# ===============================================================================

# [No.1] 1_Default_wrapper.21
# In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:379/    def construct(self, *inputs):/
funcgraph fg_21(
        %para1 : Tensor(F32)[8, 3, 32, 32]    # inputs0
        , %para2 : Tensor(I32)[8]    # inputs1
        , %para3 : Ref[Tensor(F32)][64, 3, 3, 3]    # conv1.0.weight
        , %para4 : Ref[Tensor(F32)][64, 64, 3, 3]    # conv1.2.weight
        , %para5 : Ref[Tensor(F32)][128, 64, 3, 3]    # conv2.0.weight
        , %para6 : Ref[Tensor(F32)][128, 128, 3, 3]    # conv2.2.weight
        , %para7 : Ref[Tensor(F32)][256, 128, 3, 3]    # conv3.0.weight
        , %para8 : Ref[Tensor(F32)][256, 256, 3, 3]    # conv3.2.weight
        , %para9 : Ref[Tensor(F32)][256, 256, 3, 3]    # conv3.4.weight
        , %para10 : Ref[Tensor(F32)][512, 256, 3, 3]    # conv4.0.weight
        , %para11 : Ref[Tensor(F32)][512, 512, 3, 3]    # conv4.2.weight
        , %para12 : Ref[Tensor(F32)][512, 512, 3, 3]    # conv4.4.weight
        , %para13 : Ref[Tensor(F32)][512, 512, 3, 3]    # conv5.0.weight
        , %para14 : Ref[Tensor(F32)][512, 512, 3, 3]    # conv5.2.weight
        , %para15 : Ref[Tensor(F32)][512, 512, 3, 3]    # conv5.4.weight
        , %para16 : Ref[Tensor(F32)][4096, 512]    # fc.0.weight
        , %para17 : Ref[Tensor(F32)][4096]    # fc.0.bias
        , %para18 : Ref[Tensor(F32)][4096, 4096]    # fc.3.weight
        , %para19 : Ref[Tensor(F32)][4096]    # fc.3.bias
        , %para20 : Ref[Tensor(F32)][7, 4096]    # fc.6.weight
        , %para21 : Ref[Tensor(F32)][7]    # fc.6.bias
        , %para22 : Ref[Tensor(F32)][1]    # beta1_power
        , %para23 : Ref[Tensor(F32)][1]    # beta2_power
        , %para24 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment1.conv1.0.weight
        , %para25 : Ref[Tensor(F32)][64, 64, 3, 3]    # moment1.conv1.2.weight
        , %para26 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment1.conv2.0.weight
        , %para27 : Ref[Tensor(F32)][128, 128, 3, 3]    # moment1.conv2.2.weight
        , %para28 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment1.conv3.0.weight
        , %para29 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment1.conv3.2.weight
        , %para30 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment1.conv3.4.weight
        , %para31 : Ref[Tensor(F32)][512, 256, 3, 3]    # moment1.conv4.0.weight
        , %para32 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.conv4.2.weight
        , %para33 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.conv4.4.weight
        , %para34 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.conv5.0.weight
        , %para35 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.conv5.2.weight
        , %para36 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment1.conv5.4.weight
        , %para37 : Ref[Tensor(F32)][4096, 512]    # moment1.fc.0.weight
        , %para38 : Ref[Tensor(F32)][4096]    # moment1.fc.0.bias
        , %para39 : Ref[Tensor(F32)][4096, 4096]    # moment1.fc.3.weight
        , %para40 : Ref[Tensor(F32)][4096]    # moment1.fc.3.bias
        , %para41 : Ref[Tensor(F32)][7, 4096]    # moment1.fc.6.weight
        , %para42 : Ref[Tensor(F32)][7]    # moment1.fc.6.bias
        , %para43 : Ref[Tensor(F32)][64, 3, 3, 3]    # moment2.conv1.0.weight
        , %para44 : Ref[Tensor(F32)][64, 64, 3, 3]    # moment2.conv1.2.weight
        , %para45 : Ref[Tensor(F32)][128, 64, 3, 3]    # moment2.conv2.0.weight
        , %para46 : Ref[Tensor(F32)][128, 128, 3, 3]    # moment2.conv2.2.weight
        , %para47 : Ref[Tensor(F32)][256, 128, 3, 3]    # moment2.conv3.0.weight
        , %para48 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment2.conv3.2.weight
        , %para49 : Ref[Tensor(F32)][256, 256, 3, 3]    # moment2.conv3.4.weight
        , %para50 : Ref[Tensor(F32)][512, 256, 3, 3]    # moment2.conv4.0.weight
        , %para51 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.conv4.2.weight
        , %para52 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.conv4.4.weight
        , %para53 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.conv5.0.weight
        , %para54 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.conv5.2.weight
        , %para55 : Ref[Tensor(F32)][512, 512, 3, 3]    # moment2.conv5.4.weight
        , %para56 : Ref[Tensor(F32)][4096, 512]    # moment2.fc.0.weight
        , %para57 : Ref[Tensor(F32)][4096]    # moment2.fc.0.bias
        , %para58 : Ref[Tensor(F32)][4096, 4096]    # moment2.fc.3.weight
        , %para59 : Ref[Tensor(F32)][4096]    # moment2.fc.3.bias
        , %para60 : Ref[Tensor(F32)][7, 4096]    # moment2.fc.6.weight
        , %para61 : Ref[Tensor(F32)][7]    # moment2.fc.6.bias
        , %para62 : Ref[Tensor(F32)][64, 3, 3, 3]    # vhat.conv1.0.weight
        , %para63 : Ref[Tensor(F32)][64, 64, 3, 3]    # vhat.conv1.2.weight
        , %para64 : Ref[Tensor(F32)][128, 64, 3, 3]    # vhat.conv2.0.weight
        , %para65 : Ref[Tensor(F32)][128, 128, 3, 3]    # vhat.conv2.2.weight
        , %para66 : Ref[Tensor(F32)][256, 128, 3, 3]    # vhat.conv3.0.weight
        , %para67 : Ref[Tensor(F32)][256, 256, 3, 3]    # vhat.conv3.2.weight
        , %para68 : Ref[Tensor(F32)][256, 256, 3, 3]    # vhat.conv3.4.weight
        , %para69 : Ref[Tensor(F32)][512, 256, 3, 3]    # vhat.conv4.0.weight
        , %para70 : Ref[Tensor(F32)][512, 512, 3, 3]    # vhat.conv4.2.weight
        , %para71 : Ref[Tensor(F32)][512, 512, 3, 3]    # vhat.conv4.4.weight
        , %para72 : Ref[Tensor(F32)][512, 512, 3, 3]    # vhat.conv5.0.weight
        , %para73 : Ref[Tensor(F32)][512, 512, 3, 3]    # vhat.conv5.2.weight
        , %para74 : Ref[Tensor(F32)][512, 512, 3, 3]    # vhat.conv5.4.weight
        , %para75 : Ref[Tensor(F32)][4096, 512]    # vhat.fc.0.weight
        , %para76 : Ref[Tensor(F32)][4096]    # vhat.fc.0.bias
        , %para77 : Ref[Tensor(F32)][4096, 4096]    # vhat.fc.3.weight
        , %para78 : Ref[Tensor(F32)][4096]    # vhat.fc.3.bias
        , %para79 : Ref[Tensor(F32)][7, 4096]    # vhat.fc.6.weight
        , %para80 : Ref[Tensor(F32)][7]    # vhat.fc.6.bias
        , %para81 : Ref[Tensor(F32)][]    # learning_rate
        , %para82 : Ref[Tensor(I32)][1]    # global_step
    ) {
    %1 : Tuple[Tensor(F32),Func]TupleShape((), NoShape) = FuncGraph::fg_37(%para1, %para2, UMonad[U])    #(Tensor(F32)[8, 3, 32, 32], Tensor(I32)[8], UMonadNoShape)    # fg_37=▸5_WithLossCell.37 #scope: Default
#38
    %2 : Tensor(F32)[] = Primitive::TupleGetItem{prim_type=1}(%1, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((), NoShape), I64NoShape) #scope: Default
#[CNode]39
    %3 : Tuple[Tensor(F32),Func]TupleShape((), NoShape) = FuncGraph::fg_37(%para1, %para2, UMonad[U])    #(Tensor(F32)[8, 3, 32, 32], Tensor(I32)[8], UMonadNoShape)    # fg_37=▸5_WithLossCell.37 #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %4 : UMonadNoShape = Primitive::UpdateState{prim_type=1}(UMonad[U], %3)    #(UMonadNoShape, Tuple[Tensor(F32),Func]TupleShape((), NoShape)) #scope: Default
#[CNode]40
    %5 : Tensor(F32)[1] = Primitive::Load{prim_type=1}(%para22, %4)    #(Ref[Tensor(F32)][1], UMonadNoShape) #scope: Default/optimizer-Adam
#[CNode]41
    %6 : Tensor(F32)[1] = PrimitivePy::Mul{prim_type=2}[output_names=["output"], input_names=["x", "y"]](%5, Tensor(43)[])    #(Tensor(F32)[1], Tensor(F32)[]) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:543/        beta1_power = self.beta1_power * self.beta1/#beta1_power
    %7 : Tensor(F32)[7] = Primitive::Load{prim_type=1}(%para21, %4)    #(Ref[Tensor(F32)][7], UMonadNoShape) #scope: Default
#[CNode]42
    %8 : Tensor(F32)[7, 4096] = Primitive::Load{prim_type=1}(%para20, %4)    #(Ref[Tensor(F32)][7, 4096], UMonadNoShape) #scope: Default
#[CNode]43
    %9 : Tensor(F32)[4096] = Primitive::Load{prim_type=1}(%para19, %4)    #(Ref[Tensor(F32)][4096], UMonadNoShape) #scope: Default
#[CNode]44
    %10 : Tensor(F32)[4096, 4096] = Primitive::Load{prim_type=1}(%para18, %4)    #(Ref[Tensor(F32)][4096, 4096], UMonadNoShape) #scope: Default
#[CNode]45
    %11 : Tensor(F32)[4096] = Primitive::Load{prim_type=1}(%para17, %4)    #(Ref[Tensor(F32)][4096], UMonadNoShape) #scope: Default
#[CNode]44
    %12 : Tensor(F32)[4096, 512] = Primitive::Load{prim_type=1}(%para16, %4)    #(Ref[Tensor(F32)][4096, 512], UMonadNoShape) #scope: Default
#[CNode]46
    %13 : Tensor(F32)[512, 512, 3, 3] = Primitive::Load{prim_type=1}(%para15, %4)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape) #scope: Default
#[CNode]47
    %14 : Tensor(F32)[512, 512, 3, 3] = Primitive::Load{prim_type=1}(%para14, %4)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape) #scope: Default
#[CNode]47
    %15 : Tensor(F32)[512, 512, 3, 3] = Primitive::Load{prim_type=1}(%para13, %4)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape) #scope: Default
#[CNode]47
    %16 : Tensor(F32)[512, 512, 3, 3] = Primitive::Load{prim_type=1}(%para12, %4)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape) #scope: Default
#[CNode]47
    %17 : Tensor(F32)[512, 512, 3, 3] = Primitive::Load{prim_type=1}(%para11, %4)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape) #scope: Default
#[CNode]47
    %18 : Tensor(F32)[512, 256, 3, 3] = Primitive::Load{prim_type=1}(%para10, %4)    #(Ref[Tensor(F32)][512, 256, 3, 3], UMonadNoShape) #scope: Default
#[CNode]48
    %19 : Tensor(F32)[256, 256, 3, 3] = Primitive::Load{prim_type=1}(%para9, %4)    #(Ref[Tensor(F32)][256, 256, 3, 3], UMonadNoShape) #scope: Default
#[CNode]49
    %20 : Tensor(F32)[256, 256, 3, 3] = Primitive::Load{prim_type=1}(%para8, %4)    #(Ref[Tensor(F32)][256, 256, 3, 3], UMonadNoShape) #scope: Default
#[CNode]49
    %21 : Tensor(F32)[256, 128, 3, 3] = Primitive::Load{prim_type=1}(%para7, %4)    #(Ref[Tensor(F32)][256, 128, 3, 3], UMonadNoShape) #scope: Default
#[CNode]50
    %22 : Tensor(F32)[128, 128, 3, 3] = Primitive::Load{prim_type=1}(%para6, %4)    #(Ref[Tensor(F32)][128, 128, 3, 3], UMonadNoShape) #scope: Default
#[CNode]51
    %23 : Tensor(F32)[128, 64, 3, 3] = Primitive::Load{prim_type=1}(%para5, %4)    #(Ref[Tensor(F32)][128, 64, 3, 3], UMonadNoShape) #scope: Default
#[CNode]52
    %24 : Tensor(F32)[64, 64, 3, 3] = Primitive::Load{prim_type=1}(%para4, %4)    #(Ref[Tensor(F32)][64, 64, 3, 3], UMonadNoShape) #scope: Default
#[CNode]53
    %25 : Tensor(F32)[64, 3, 3, 3] = Primitive::Load{prim_type=1}(%para3, %4)    #(Ref[Tensor(F32)][64, 3, 3, 3], UMonadNoShape) #scope: Default
#[CNode]54
    %26 : Tuple[Tensor(F32)*20]TupleShape((7), (7, 4096), (4096), (4096, 4096), (4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (256, 256, 3, 3), (256, 128, 3, 3), (128, 128, 3, 3), (128, 64, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (1)) = Primitive::MakeTuple{prim_type=1}(%7, %8, %9, %10, %11, %12, %13, %14, %15, %16, %17, %18, %19, %20, %21, %22, %23, %24, %25, %5)    #(Tensor(F32)[7], Tensor(F32)[7, 4096], Tensor(F32)[4096], Tensor(F32)[4096, 4096], Tensor(F32)[4096], Tensor(F32)[4096, 512], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 256, 3, 3], Tensor(F32)[256, 256, 3, 3], Tensor(F32)[256, 256, 3, 3], Tensor(F32)[256, 128, 3, 3], Tensor(F32)[128, 128, 3, 3], Tensor(F32)[128, 64, 3, 3], Tensor(F32)[64, 64, 3, 3], Tensor(F32)[64, 3, 3, 3], Tensor(F32)[1]) #scope: Default/optimizer-Adam
#[CNode]55
    %27 : UMonadNoShape = Primitive::UpdateState{prim_type=1}(%4, %26)    #(UMonadNoShape, Tuple[Tensor(F32)*20]TupleShape((7), (7, 4096), (4096), (4096, 4096), (4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (256, 256, 3, 3), (256, 128, 3, 3), (128, 128, 3, 3), (128, 64, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (1))) #scope: Default/optimizer-Adam
#[CNode]56
    %28 : Tensor(F32)[1] = PrimitivePy::Assign{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), input_names=["ref", "value"]](%para22, %6, %27)    #(Ref[Tensor(F32)][1], Tensor(F32)[1], UMonadNoShape) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/function/parameter_func.py:57/    return assign_(variable, value)/#[CNode]57
    %29 : UMonadNoShape = Primitive::UpdateState{prim_type=1}(%27, %28)    #(UMonadNoShape, Tensor(F32)[1]) #scope: Default/optimizer-Adam
#[CNode]58
    %30 : Tensor(F32)[1] = Primitive::Load{prim_type=1}(%para23, %29)    #(Ref[Tensor(F32)][1], UMonadNoShape) #scope: Default/optimizer-Adam
#[CNode]59
    %31 : Tensor(F32)[1] = PrimitivePy::Mul{prim_type=2}[output_names=["output"], input_names=["x", "y"]](%30, Tensor(43)[])    #(Tensor(F32)[1], Tensor(F32)[]) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:545/        beta2_power = self.beta2_power * self.beta2/#beta2_power
    %32 : FuncNoShape = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_60)    #(FuncNoShape)    # fg_60=228_tensor_deduplicate_indice_slices.60 #scope: Default/optimizer-Adam
#[CNode]61
    %33 : FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%3, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((), NoShape), I64NoShape) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads

#------------------------> 0
    %34 = %33(Tensor(43)[])    #(Tensor(F32)[]) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %35 = Primitive::TupleGetItem{prim_type=1}(%34, I64(0))    #(Undefined, Undefined) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:382/        grads = self.grad(self.network, self.weights)(*inputs, sens)/#grads
    %36 = PrimitivePy::RefToEmbed{prim_type=1}(%para3)    #(Ref[Tensor(F32)][64, 3, 3, 3]) #scope: Default
#[CNode]62
    %37 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%25)    #(Tensor(F32)[64, 3, 3, 3]) #scope: Default
#[CNode]62
    %38 = PrimitivePy::EnvironGet{prim_type=1}(%35, %36, %37)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %39 = %32(%38)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %40 = Primitive::UpdateState{prim_type=1}(%29, %30)    #(UMonadNoShape, Tensor(F32)[1]) #scope: Default/optimizer-Adam
#[CNode]63
    %41 = PrimitivePy::Assign{prim_type=1}[output_names=["output"], side_effect_mem=Bool(1), input_names=["ref", "value"]](%para23, %31, %40)    #(Ref[Tensor(F32)][1], Tensor(F32)[1], Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/function/parameter_func.py:57/    return assign_(variable, value)/#[CNode]57
    %42 = Primitive::UpdateState{prim_type=1}(%40, %41)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]58
    %43 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para3, %para24, %para43, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %39, %42)    #(Ref[Tensor(F32)][64, 3, 3, 3], Ref[Tensor(F32)][64, 3, 3, 3], Ref[Tensor(F32)][64, 3, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %44 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %43)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %45 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_65)    #(Undefined)    # fg_65=231_tensor_deduplicate_indice_slices.65 #scope: Default/optimizer-Adam
#[CNode]66
    %46 = PrimitivePy::RefToEmbed{prim_type=1}(%para4)    #(Ref[Tensor(F32)][64, 64, 3, 3]) #scope: Default
#[CNode]62
    %47 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%24)    #(Tensor(F32)[64, 64, 3, 3]) #scope: Default
#[CNode]62
    %48 = PrimitivePy::EnvironGet{prim_type=1}(%35, %46, %47)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %49 = %45(%48)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %50 = Primitive::UpdateState{prim_type=1}(%42, %43)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]67
    %51 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para4, %para25, %para44, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %49, %50)    #(Ref[Tensor(F32)][64, 64, 3, 3], Ref[Tensor(F32)][64, 64, 3, 3], Ref[Tensor(F32)][64, 64, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %52 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %51)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %53 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_68)    #(Undefined)    # fg_68=234_tensor_deduplicate_indice_slices.68 #scope: Default/optimizer-Adam
#[CNode]69
    %54 = PrimitivePy::RefToEmbed{prim_type=1}(%para5)    #(Ref[Tensor(F32)][128, 64, 3, 3]) #scope: Default
#[CNode]62
    %55 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%23)    #(Tensor(F32)[128, 64, 3, 3]) #scope: Default
#[CNode]62
    %56 = PrimitivePy::EnvironGet{prim_type=1}(%35, %54, %55)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %57 = %53(%56)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %58 = Primitive::UpdateState{prim_type=1}(%50, %51)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]70
    %59 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para5, %para26, %para45, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %57, %58)    #(Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128, 64, 3, 3], Ref[Tensor(F32)][128, 64, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %60 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %59)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %61 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_71)    #(Undefined)    # fg_71=237_tensor_deduplicate_indice_slices.71 #scope: Default/optimizer-Adam
#[CNode]72
    %62 = PrimitivePy::RefToEmbed{prim_type=1}(%para6)    #(Ref[Tensor(F32)][128, 128, 3, 3]) #scope: Default
#[CNode]62
    %63 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%22)    #(Tensor(F32)[128, 128, 3, 3]) #scope: Default
#[CNode]62
    %64 = PrimitivePy::EnvironGet{prim_type=1}(%35, %62, %63)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %65 = %61(%64)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %66 = Primitive::UpdateState{prim_type=1}(%58, %59)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]73
    %67 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para6, %para27, %para46, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %65, %66)    #(Ref[Tensor(F32)][128, 128, 3, 3], Ref[Tensor(F32)][128, 128, 3, 3], Ref[Tensor(F32)][128, 128, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %68 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %67)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %69 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_74)    #(Undefined)    # fg_74=240_tensor_deduplicate_indice_slices.74 #scope: Default/optimizer-Adam
#[CNode]75
    %70 = PrimitivePy::RefToEmbed{prim_type=1}(%para7)    #(Ref[Tensor(F32)][256, 128, 3, 3]) #scope: Default
#[CNode]62
    %71 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%21)    #(Tensor(F32)[256, 128, 3, 3]) #scope: Default
#[CNode]62
    %72 = PrimitivePy::EnvironGet{prim_type=1}(%35, %70, %71)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %73 = %69(%72)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %74 = Primitive::UpdateState{prim_type=1}(%66, %67)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]76
    %75 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para7, %para28, %para47, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %73, %74)    #(Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256, 128, 3, 3], Ref[Tensor(F32)][256, 128, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %76 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %75)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %77 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_77)    #(Undefined)    # fg_77=243_tensor_deduplicate_indice_slices.77 #scope: Default/optimizer-Adam
#[CNode]78
    %78 = PrimitivePy::RefToEmbed{prim_type=1}(%para8)    #(Ref[Tensor(F32)][256, 256, 3, 3]) #scope: Default
#[CNode]62
    %79 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%20)    #(Tensor(F32)[256, 256, 3, 3]) #scope: Default
#[CNode]62
    %80 = PrimitivePy::EnvironGet{prim_type=1}(%35, %78, %79)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %81 = %77(%80)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %82 = Primitive::UpdateState{prim_type=1}(%74, %75)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]79
    %83 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para8, %para29, %para48, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %81, %82)    #(Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256, 256, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %84 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %83)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %85 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_77)    #(Undefined)    # fg_77=243_tensor_deduplicate_indice_slices.77 #scope: Default/optimizer-Adam
#[CNode]80
    %86 = PrimitivePy::RefToEmbed{prim_type=1}(%para9)    #(Ref[Tensor(F32)][256, 256, 3, 3]) #scope: Default
#[CNode]62
    %87 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%19)    #(Tensor(F32)[256, 256, 3, 3]) #scope: Default
#[CNode]62
    %88 = PrimitivePy::EnvironGet{prim_type=1}(%35, %86, %87)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]62
    %89 = %85(%88)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %90 = Primitive::UpdateState{prim_type=1}(%82, %83)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]81
    %91 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para9, %para30, %para49, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %89, %90)    #(Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256, 256, 3, 3], Ref[Tensor(F32)][256, 256, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %92 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %91)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %93 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_82)    #(Undefined)    # fg_82=247_tensor_deduplicate_indice_slices.82 #scope: Default/optimizer-Adam
#[CNode]83
    %94 = PrimitivePy::RefToEmbed{prim_type=1}(%para10)    #(Ref[Tensor(F32)][512, 256, 3, 3]) #scope: Default
#[CNode]84
    %95 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%18)    #(Tensor(F32)[512, 256, 3, 3]) #scope: Default
#[CNode]84
    %96 = PrimitivePy::EnvironGet{prim_type=1}(%35, %94, %95)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %97 = %93(%96)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %98 = Primitive::UpdateState{prim_type=1}(%90, %91)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]81
    %99 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para10, %para31, %para50, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %97, %98)    #(Ref[Tensor(F32)][512, 256, 3, 3], Ref[Tensor(F32)][512, 256, 3, 3], Ref[Tensor(F32)][512, 256, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %100 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %99)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %101 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_85)    #(Undefined)    # fg_85=250_tensor_deduplicate_indice_slices.85 #scope: Default/optimizer-Adam
#[CNode]86
    %102 = PrimitivePy::RefToEmbed{prim_type=1}(%para11)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]84
    %103 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%17)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]84
    %104 = PrimitivePy::EnvironGet{prim_type=1}(%35, %102, %103)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %105 = %101(%104)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %106 = Primitive::UpdateState{prim_type=1}(%98, %99)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]87
    %107 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para11, %para32, %para51, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %105, %106)    #(Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %108 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %107)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %109 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_85)    #(Undefined)    # fg_85=250_tensor_deduplicate_indice_slices.85 #scope: Default/optimizer-Adam
#[CNode]88
    %110 = PrimitivePy::RefToEmbed{prim_type=1}(%para12)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]84
    %111 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%16)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]84
    %112 = PrimitivePy::EnvironGet{prim_type=1}(%35, %110, %111)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %113 = %109(%112)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %114 = Primitive::UpdateState{prim_type=1}(%106, %107)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]89
    %115 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para12, %para33, %para52, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %113, %114)    #(Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %116 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %115)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %117 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_85)    #(Undefined)    # fg_85=250_tensor_deduplicate_indice_slices.85 #scope: Default/optimizer-Adam
#[CNode]90
    %118 = PrimitivePy::RefToEmbed{prim_type=1}(%para13)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]84
    %119 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%15)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]84
    %120 = PrimitivePy::EnvironGet{prim_type=1}(%35, %118, %119)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %121 = %117(%120)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %122 = Primitive::UpdateState{prim_type=1}(%114, %115)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]89
    %123 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para13, %para34, %para53, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %121, %122)    #(Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %124 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %123)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %125 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_85)    #(Undefined)    # fg_85=250_tensor_deduplicate_indice_slices.85 #scope: Default/optimizer-Adam
#[CNode]91
    %126 = PrimitivePy::RefToEmbed{prim_type=1}(%para14)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]84
    %127 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%14)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]84
    %128 = PrimitivePy::EnvironGet{prim_type=1}(%35, %126, %127)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %129 = %125(%128)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %130 = Primitive::UpdateState{prim_type=1}(%122, %123)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]89
    %131 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para14, %para35, %para54, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %129, %130)    #(Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %132 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %131)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %133 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_85)    #(Undefined)    # fg_85=250_tensor_deduplicate_indice_slices.85 #scope: Default/optimizer-Adam
#[CNode]92
    %134 = PrimitivePy::RefToEmbed{prim_type=1}(%para15)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]84
    %135 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%13)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]84
    %136 = PrimitivePy::EnvironGet{prim_type=1}(%35, %134, %135)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]84
    %137 = %133(%136)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %138 = Primitive::UpdateState{prim_type=1}(%130, %131)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]89
    %139 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para15, %para36, %para55, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %137, %138)    #(Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Ref[Tensor(F32)][512, 512, 3, 3], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %140 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %139)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %141 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_93)    #(Undefined)    # fg_93=257_tensor_deduplicate_indice_slices.93 #scope: Default/optimizer-Adam
#[CNode]94
    %142 = PrimitivePy::RefToEmbed{prim_type=1}(%para16)    #(Ref[Tensor(F32)][4096, 512]) #scope: Default
#[CNode]95
    %143 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%12)    #(Tensor(F32)[4096, 512]) #scope: Default
#[CNode]95
    %144 = PrimitivePy::EnvironGet{prim_type=1}(%35, %142, %143)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]95
    %145 = %141(%144)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %146 = Primitive::UpdateState{prim_type=1}(%138, %139)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]89
    %147 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para16, %para37, %para56, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %145, %146)    #(Ref[Tensor(F32)][4096, 512], Ref[Tensor(F32)][4096, 512], Ref[Tensor(F32)][4096, 512], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %148 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %147)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %149 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_96)    #(Undefined)    # fg_96=260_tensor_deduplicate_indice_slices.96 #scope: Default/optimizer-Adam
#[CNode]97
    %150 = PrimitivePy::RefToEmbed{prim_type=1}(%para17)    #(Ref[Tensor(F32)][4096]) #scope: Default
#[CNode]95
    %151 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%11)    #(Tensor(F32)[4096]) #scope: Default
#[CNode]95
    %152 = PrimitivePy::EnvironGet{prim_type=1}(%35, %150, %151)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]95
    %153 = %149(%152)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %154 = Primitive::UpdateState{prim_type=1}(%146, %147)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]98
    %155 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para17, %para38, %para57, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %153, %154)    #(Ref[Tensor(F32)][4096], Ref[Tensor(F32)][4096], Ref[Tensor(F32)][4096], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %156 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %155)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %157 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_99)    #(Undefined)    # fg_99=263_tensor_deduplicate_indice_slices.99 #scope: Default/optimizer-Adam
#[CNode]100
    %158 = PrimitivePy::RefToEmbed{prim_type=1}(%para18)    #(Ref[Tensor(F32)][4096, 4096]) #scope: Default
#[CNode]95
    %159 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%10)    #(Tensor(F32)[4096, 4096]) #scope: Default
#[CNode]95
    %160 = PrimitivePy::EnvironGet{prim_type=1}(%35, %158, %159)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]95
    %161 = %157(%160)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %162 = Primitive::UpdateState{prim_type=1}(%154, %155)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]101
    %163 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para18, %para39, %para58, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %161, %162)    #(Ref[Tensor(F32)][4096, 4096], Ref[Tensor(F32)][4096, 4096], Ref[Tensor(F32)][4096, 4096], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %164 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %163)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %165 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_96)    #(Undefined)    # fg_96=260_tensor_deduplicate_indice_slices.96 #scope: Default/optimizer-Adam
#[CNode]102
    %166 = PrimitivePy::RefToEmbed{prim_type=1}(%para19)    #(Ref[Tensor(F32)][4096]) #scope: Default
#[CNode]95
    %167 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%9)    #(Tensor(F32)[4096]) #scope: Default
#[CNode]95
    %168 = PrimitivePy::EnvironGet{prim_type=1}(%35, %166, %167)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]95
    %169 = %165(%168)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %170 = Primitive::UpdateState{prim_type=1}(%162, %163)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]103
    %171 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para19, %para40, %para59, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %169, %170)    #(Ref[Tensor(F32)][4096], Ref[Tensor(F32)][4096], Ref[Tensor(F32)][4096], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %172 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %171)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %173 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_104)    #(Undefined)    # fg_104=267_tensor_deduplicate_indice_slices.104 #scope: Default/optimizer-Adam
#[CNode]105
    %174 = PrimitivePy::RefToEmbed{prim_type=1}(%para20)    #(Ref[Tensor(F32)][7, 4096]) #scope: Default
#[CNode]106
    %175 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%8)    #(Tensor(F32)[7, 4096]) #scope: Default
#[CNode]106
    %176 = PrimitivePy::EnvironGet{prim_type=1}(%35, %174, %175)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]106
    %177 = %173(%176)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %178 = Primitive::UpdateState{prim_type=1}(%170, %171)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]101
    %179 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para20, %para41, %para60, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %177, %178)    #(Ref[Tensor(F32)][7, 4096], Ref[Tensor(F32)][7, 4096], Ref[Tensor(F32)][7, 4096], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %180 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %179)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %181 = Primitive::Partial{prim_type=1}[side_effect_propagate=I64(1)](FuncGraph::fg_107)    #(Undefined)    # fg_107=270_tensor_deduplicate_indice_slices.107 #scope: Default/optimizer-Adam
#[CNode]108
    %182 = PrimitivePy::RefToEmbed{prim_type=1}(%para21)    #(Ref[Tensor(F32)][7]) #scope: Default
#[CNode]106
    %183 = PrimitivePy::ZerosLike{prim_type=1}[output_names=["y"], input_names=["x"]](%7)    #(Tensor(F32)[7]) #scope: Default
#[CNode]106
    %184 = PrimitivePy::EnvironGet{prim_type=1}(%35, %182, %183)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]106
    %185 = %181(%184)    #(Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/optimizer.py:465/            gradients = self.map_(F.partial(_indices_deduplicate), gradients)/#gradients
    %186 = Primitive::UpdateState{prim_type=1}(%178, %179)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]109
    %187 = PrimitivePy::Adam{prim_type=1}[side_effect_mem=Bool(1), use_nesterov=Bool(0), use_locking=Bool(0)](%para21, %para42, %para61, %6, %31, %para81, Tensor(43)[], Tensor(43)[], Tensor(43)[], %185, %186)    #(Ref[Tensor(F32)][7], Ref[Tensor(F32)][7], Ref[Tensor(F32)][7], Tensor(F32)[1], Tensor(F32)[1], Ref[Tensor(F32)][], Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#[CNode]64
    %188 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](Bool(1), %187)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:278/            success = F.depend(success, opt(param, moment1, moment2, beta1_power, beta2_power, lr, beta1, beta2,/#success
    %189 = Primitive::MakeTuple{prim_type=1}(%44, %52, %60, %68, %76, %84, %92, %100, %108, %116, %124, %132, %140, %148, %156, %164, %172, %180, %188)    #(Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined, Undefined) #scope: Default/optimizer-Adam
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/optim/adam.py:573/                success = self.map_(F.partial(_adam_opt, self.opt, self.sparse_opt, self._ps_push, self._ps_pull,/#success
    %190 = PrimitivePy::Depend{prim_type=1}[side_effect_propagate=I64(1)](%2, %189)    #(Tensor(F32)[], Undefined) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:384/        loss = F.depend(loss, self.optimizer(grads))/#loss
    %191 = Primitive::UpdateState{prim_type=1}(%186, %187)    #(Undefined, Undefined) #scope: Default/optimizer-Adam
#[CNode]110
    %192 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%190, %191)    #(Undefined, Undefined) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:384/        loss = F.depend(loss, self.optimizer(grads))/#loss
    Primitive::Return{prim_type=1}(%192)    #(Undefined) #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:385/        return loss/#111
}


# [No.2] ◂5_WithLossCell.34
# In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:116/    def construct(self, data, label):/
funcgraph fg_34[fg_37](
        %para83 : Tensor(F32)[]    # [Parameter]35
    ) {
    %1 : EnvTypeNoShape = Primitive::EnvironCreate{prim_type=1}() #scope: Default
#[CNode]112
    %2 : SymTypeNoShape = Primitive::embed{prim_type=1}(%para13)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]113
    %3 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape) = FuncGraph::fg_26(%para13, %para-1)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape)    # fg_26=▸Load.26 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#▲[CNode]114
    %4 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%3, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]115
    %5 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((64, 3, 3, 3), NoShape) = FuncGraph::fg_116(%para3, %para-1)    #(Ref[Tensor(F32)][64, 3, 3, 3], UMonadNoShape)    # fg_116=▸Load.116 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#▲[CNode]117
    %6 : $(▸5_WithLossCell.37):Tensor(F32)[64, 3, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%5, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((64, 3, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]118
    %7 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape) = FuncGraph::fg_119(%para-1, %6)    #(Tensor(F32)[8, 3, 32, 32], Tensor(F32)[64, 3, 3, 3])    # fg_119=▸Conv2D.119 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %8 : $(▸5_WithLossCell.37):Tensor(F32)[8, 64, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%7, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]120
    %9 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape) = FuncGraph::fg_121(%8)    #(Tensor(F32)[8, 64, 32, 32])    # fg_121=▸ReLU.121 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]122
    %10 : $(▸5_WithLossCell.37):Tensor(F32)[8, 64, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%9, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
#[CNode]123
    %11 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((64, 64, 3, 3), NoShape) = FuncGraph::fg_124(%para4, %para-1)    #(Ref[Tensor(F32)][64, 64, 3, 3], UMonadNoShape)    # fg_124=▸Load.124 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#▲[CNode]125
    %12 : $(▸5_WithLossCell.37):Tensor(F32)[64, 64, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%11, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((64, 64, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]126
    %13 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape) = FuncGraph::fg_127(%10, %12)    #(Tensor(F32)[8, 64, 32, 32], Tensor(F32)[64, 64, 3, 3])    # fg_127=▸Conv2D.127 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %14 : $(▸5_WithLossCell.37):Tensor(F32)[8, 64, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%13, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]128
    %15 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape) = FuncGraph::fg_129(%14)    #(Tensor(F32)[8, 64, 32, 32])    # fg_129=▸ReLU.129 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]130
    %16 : $(▸5_WithLossCell.37):Tensor(F32)[8, 64, 32, 32] = Primitive::TupleGetItem{prim_type=1}(%15, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
#[CNode]131
    %17 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 64, 16, 16), NoShape) = FuncGraph::fg_132(%16)    #(Tensor(F32)[8, 64, 32, 32])    # fg_132=▸MaxPool.132 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:148/        out = self.max_pool(x)/#▲out
    %18 : $(▸5_WithLossCell.37):Tensor(F32)[8, 64, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%17, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
#[CNode]133
    %19 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((128, 64, 3, 3), NoShape) = FuncGraph::fg_134(%para5, %para-1)    #(Ref[Tensor(F32)][128, 64, 3, 3], UMonadNoShape)    # fg_134=▸Load.134 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#▲[CNode]135
    %20 : $(▸5_WithLossCell.37):Tensor(F32)[128, 64, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%19, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((128, 64, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]136
    %21 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape) = FuncGraph::fg_137(%18, %20)    #(Tensor(F32)[8, 64, 16, 16], Tensor(F32)[128, 64, 3, 3])    # fg_137=▸Conv2D.137 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %22 : $(▸5_WithLossCell.37):Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%21, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]138
    %23 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape) = FuncGraph::fg_139(%22)    #(Tensor(F32)[8, 128, 16, 16])    # fg_139=▸ReLU.139 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]140
    %24 : $(▸5_WithLossCell.37):Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%23, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
#[CNode]141
    %25 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((128, 128, 3, 3), NoShape) = FuncGraph::fg_142(%para6, %para-1)    #(Ref[Tensor(F32)][128, 128, 3, 3], UMonadNoShape)    # fg_142=▸Load.142 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#▲[CNode]143
    %26 : $(▸5_WithLossCell.37):Tensor(F32)[128, 128, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%25, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((128, 128, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]144
    %27 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape) = FuncGraph::fg_145(%24, %26)    #(Tensor(F32)[8, 128, 16, 16], Tensor(F32)[128, 128, 3, 3])    # fg_145=▸Conv2D.145 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %28 : $(▸5_WithLossCell.37):Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%27, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]146
    %29 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape) = FuncGraph::fg_147(%28)    #(Tensor(F32)[8, 128, 16, 16])    # fg_147=▸ReLU.147 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]148
    %30 : $(▸5_WithLossCell.37):Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%29, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
#[CNode]149
    %31 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 128, 8, 8), NoShape) = FuncGraph::fg_150(%30)    #(Tensor(F32)[8, 128, 16, 16])    # fg_150=▸MaxPool.150 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:148/        out = self.max_pool(x)/#▲out
    %32 : $(▸5_WithLossCell.37):Tensor(F32)[8, 128, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%31, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
#[CNode]151
    %33 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((256, 128, 3, 3), NoShape) = FuncGraph::fg_152(%para7, %para-1)    #(Ref[Tensor(F32)][256, 128, 3, 3], UMonadNoShape)    # fg_152=▸Load.152 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#▲[CNode]153
    %34 : $(▸5_WithLossCell.37):Tensor(F32)[256, 128, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%33, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((256, 128, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]154
    %35 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_155(%32, %34)    #(Tensor(F32)[8, 128, 8, 8], Tensor(F32)[256, 128, 3, 3])    # fg_155=▸Conv2D.155 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %36 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%35, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]156
    %37 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_157(%36)    #(Tensor(F32)[8, 256, 8, 8])    # fg_157=▸ReLU.157 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]158
    %38 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%37, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
#[CNode]159
    %39 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape) = FuncGraph::fg_22(%para8, %para-1)    #(Ref[Tensor(F32)][256, 256, 3, 3], UMonadNoShape)    # fg_22=▸Load.22 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#▲[CNode]160
    %40 : $(▸5_WithLossCell.37):Tensor(F32)[256, 256, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%39, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]161
    %41 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_23(%38, %40)    #(Tensor(F32)[8, 256, 8, 8], Tensor(F32)[256, 256, 3, 3])    # fg_23=▸Conv2D.23 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %42 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%41, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]162
    %43 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_163(%42)    #(Tensor(F32)[8, 256, 8, 8])    # fg_163=▸ReLU.163 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]164
    %44 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%43, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
#[CNode]165
    %45 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape) = FuncGraph::fg_22(%para9, %para-1)    #(Ref[Tensor(F32)][256, 256, 3, 3], UMonadNoShape)    # fg_22=▸Load.22 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#▲[CNode]160
    %46 : $(▸5_WithLossCell.37):Tensor(F32)[256, 256, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%45, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]166
    %47 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_23(%44, %46)    #(Tensor(F32)[8, 256, 8, 8], Tensor(F32)[256, 256, 3, 3])    # fg_23=▸Conv2D.23 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %48 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%47, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]167
    %49 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape) = FuncGraph::fg_168(%48)    #(Tensor(F32)[8, 256, 8, 8])    # fg_168=▸ReLU.168 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]169
    %50 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%49, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
#[CNode]170
    %51 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 256, 4, 4), NoShape) = FuncGraph::fg_171(%50)    #(Tensor(F32)[8, 256, 8, 8])    # fg_171=▸MaxPool.171 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:148/        out = self.max_pool(x)/#▲out
    %52 : $(▸5_WithLossCell.37):Tensor(F32)[8, 256, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%51, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
#[CNode]172
    %53 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 256, 3, 3), NoShape) = FuncGraph::fg_173(%para10, %para-1)    #(Ref[Tensor(F32)][512, 256, 3, 3], UMonadNoShape)    # fg_173=▸Load.173 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#▲[CNode]174
    %54 : $(▸5_WithLossCell.37):Tensor(F32)[512, 256, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%53, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 256, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]175
    %55 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_176(%52, %54)    #(Tensor(F32)[8, 256, 4, 4], Tensor(F32)[512, 256, 3, 3])    # fg_176=▸Conv2D.176 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %56 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%55, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]177
    %57 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_178(%56)    #(Tensor(F32)[8, 512, 4, 4])    # fg_178=▸ReLU.178 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]179
    %58 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%57, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
#[CNode]180
    %59 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape) = FuncGraph::fg_24(%para11, %para-1)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape)    # fg_24=▸Load.24 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#▲[CNode]181
    %60 : $(▸5_WithLossCell.37):Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%59, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]182
    %61 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_25(%58, %60)    #(Tensor(F32)[8, 512, 4, 4], Tensor(F32)[512, 512, 3, 3])    # fg_25=▸Conv2D.25 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %62 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%61, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]183
    %63 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_184(%62)    #(Tensor(F32)[8, 512, 4, 4])    # fg_184=▸ReLU.184 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]185
    %64 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%63, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
#[CNode]186
    %65 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape) = FuncGraph::fg_24(%para12, %para-1)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape)    # fg_24=▸Load.24 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#▲[CNode]181
    %66 : $(▸5_WithLossCell.37):Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%65, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]187
    %67 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_25(%64, %66)    #(Tensor(F32)[8, 512, 4, 4], Tensor(F32)[512, 512, 3, 3])    # fg_25=▸Conv2D.25 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %68 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%67, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]188
    %69 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape) = FuncGraph::fg_189(%68)    #(Tensor(F32)[8, 512, 4, 4])    # fg_189=▸ReLU.189 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]190
    %70 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%69, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
#[CNode]191
    %71 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_192(%70)    #(Tensor(F32)[8, 512, 4, 4])    # fg_192=▸MaxPool.192 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:148/        out = self.max_pool(x)/#▲out
    %72 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%71, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
#[CNode]193
    %73 : $(▸5_WithLossCell.37):Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%3, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]194
    %74 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_27(%72, %73)    #(Tensor(F32)[8, 512, 2, 2], Tensor(F32)[512, 512, 3, 3])    # fg_27=▸Conv2D.27 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %75 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%74, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]195
    %76 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%74, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]196
    %77 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_197(%76)    #(Tensor(F32)[8, 512, 2, 2])    # fg_197=▸ReLU.197 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]198
    %78 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%77, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
#[CNode]199
    %79 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%77, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
#[CNode]200
    %80 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape) = FuncGraph::fg_26(%para14, %para-1)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape)    # fg_26=▸Load.26 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#▲[CNode]114
    %81 : $(▸5_WithLossCell.37):Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%80, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]201
    %82 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_27(%79, %81)    #(Tensor(F32)[8, 512, 2, 2], Tensor(F32)[512, 512, 3, 3])    # fg_27=▸Conv2D.27 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %83 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%82, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]202
    %84 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%82, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]203
    %85 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_204(%84)    #(Tensor(F32)[8, 512, 2, 2])    # fg_204=▸ReLU.204 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]205
    %86 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%85, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
#[CNode]206
    %87 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%85, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
#[CNode]207
    %88 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape) = FuncGraph::fg_26(%para15, %para-1)    #(Ref[Tensor(F32)][512, 512, 3, 3], UMonadNoShape)    # fg_26=▸Load.26 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#▲[CNode]114
    %89 : $(▸5_WithLossCell.37):Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%88, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]208
    %90 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_27(%87, %89)    #(Tensor(F32)[8, 512, 2, 2], Tensor(F32)[512, 512, 3, 3])    # fg_27=▸Conv2D.27 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/conv.py:308/        output = self.conv2d(x, self.weight)/#▲output
    %91 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%90, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]209
    %92 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%90, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]210
    %93 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape) = FuncGraph::fg_211(%92)    #(Tensor(F32)[8, 512, 2, 2])    # fg_211=▸ReLU.211 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]212
    %94 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%93, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
#[CNode]213
    %95 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%93, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
#[CNode]214
    %96 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512, 1, 1), NoShape) = FuncGraph::fg_215(%95)    #(Tensor(F32)[8, 512, 2, 2])    # fg_215=▸MaxPool.215 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/pooling.py:148/        out = self.max_pool(x)/#▲out
    %97 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%96, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 1, 1), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
#[CNode]216
    %98 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512, 1, 1] = Primitive::TupleGetItem{prim_type=1}(%96, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 1, 1), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
#[CNode]217
    %99 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 512), NoShape) = FuncGraph::fg_218(%98, (I64(8), I64(-1)))    #(Tensor(F32)[8, 512, 1, 1], Tuple[I64*2]TupleShape(NoShape, NoShape))    # fg_218=▸Reshape.218 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:867/    return reshape_(input_x, input_shape)/#▲[CNode]219
    %100 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%99, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
#[CNode]220
    %101 : $(▸5_WithLossCell.37):Tensor(F32)[8, 512] = Primitive::TupleGetItem{prim_type=1}(%99, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
#[CNode]221
    %102 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((4096, 512), NoShape) = FuncGraph::fg_222(%para16, %para-1)    #(Ref[Tensor(F32)][4096, 512], UMonadNoShape)    # fg_222=▸Load.222 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#▲[CNode]223
    %103 : $(▸5_WithLossCell.37):Tensor(F32)[4096, 512] = Primitive::TupleGetItem{prim_type=1}(%102, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((4096, 512), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]224
    %104 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_225(%101, %103)    #(Tensor(F32)[8, 512], Tensor(F32)[4096, 512])    # fg_225=▸MatMul.225 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:468/        x = self.matmul(x, self.weight)/#▲x
    %105 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%104, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]226
    %106 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%104, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]227
    %107 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((4096), NoShape) = FuncGraph::fg_228(%para17, %para-1)    #(Ref[Tensor(F32)][4096], UMonadNoShape)    # fg_228=▸Load.228 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#▲[CNode]229
    %108 : $(▸5_WithLossCell.37):Tensor(F32)[4096] = Primitive::TupleGetItem{prim_type=1}(%107, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]230
    %109 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_231(%106, %108)    #(Tensor(F32)[8, 4096], Tensor(F32)[4096])    # fg_231=▸BiasAdd.231 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:470/            x = self.bias_add(x, self.bias)/#▲x
    %110 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%109, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]232
    %111 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%109, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]233
    %112 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_234(%111)    #(Tensor(F32)[8, 4096])    # fg_234=▸ReLU.234 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]235
    %113 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%112, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
#[CNode]236
    %114 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%112, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
#[CNode]237
    %115 : $(▸5_WithLossCell.37):Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape) = FuncGraph::fg_238(%114)    #(Tensor(F32)[8, 4096])    # fg_238=▸Dropout.238 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:178/        out, _ = self.dropout(x)/#▲[CNode]239
    %116 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%115, I64(1))    #(Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]240
    %117 : $(▸5_WithLossCell.37):Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)) = Primitive::TupleGetItem{prim_type=1}(%115, I64(0))    #(Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]241
    %118 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_242(%117, I64(0))    #(Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)), I64NoShape)    # fg_242=▸TupleGetItem.242 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:178/        out, _ = self.dropout(x)/#▲out
    %119 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%118, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]243
    %120 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%118, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]244
    %121 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((4096, 4096), NoShape) = FuncGraph::fg_245(%para18, %para-1)    #(Ref[Tensor(F32)][4096, 4096], UMonadNoShape)    # fg_245=▸Load.245 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#▲[CNode]246
    %122 : $(▸5_WithLossCell.37):Tensor(F32)[4096, 4096] = Primitive::TupleGetItem{prim_type=1}(%121, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((4096, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]247
    %123 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_248(%120, %122)    #(Tensor(F32)[8, 4096], Tensor(F32)[4096, 4096])    # fg_248=▸MatMul.248 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:468/        x = self.matmul(x, self.weight)/#▲x
    %124 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%123, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]249
    %125 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%123, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]250
    %126 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((4096), NoShape) = FuncGraph::fg_251(%para19, %para-1)    #(Ref[Tensor(F32)][4096], UMonadNoShape)    # fg_251=▸Load.251 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#▲[CNode]252
    %127 : $(▸5_WithLossCell.37):Tensor(F32)[4096] = Primitive::TupleGetItem{prim_type=1}(%126, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]253
    %128 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_254(%125, %127)    #(Tensor(F32)[8, 4096], Tensor(F32)[4096])    # fg_254=▸BiasAdd.254 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:470/            x = self.bias_add(x, self.bias)/#▲x
    %129 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%128, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]255
    %130 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%128, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]256
    %131 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_257(%130)    #(Tensor(F32)[8, 4096])    # fg_257=▸ReLU.257 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:362/        return self.relu(x)/#▲[CNode]258
    %132 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%131, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
#[CNode]259
    %133 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%131, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
#[CNode]260
    %134 : $(▸5_WithLossCell.37):Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape) = FuncGraph::fg_261(%133)    #(Tensor(F32)[8, 4096])    # fg_261=▸Dropout.261 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:178/        out, _ = self.dropout(x)/#▲[CNode]262
    %135 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%134, I64(1))    #(Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]263
    %136 : $(▸5_WithLossCell.37):Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)) = Primitive::TupleGetItem{prim_type=1}(%134, I64(0))    #(Tuple[Tuple[Tensor(F32)*2],Func]TupleShape(TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]264
    %137 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape) = FuncGraph::fg_265(%136, I64(0))    #(Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)), I64NoShape)    # fg_265=▸TupleGetItem.265 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:178/        out, _ = self.dropout(x)/#▲out
    %138 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%137, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]266
    %139 : $(▸5_WithLossCell.37):Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%137, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]267
    %140 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((7, 4096), NoShape) = FuncGraph::fg_268(%para20, %para-1)    #(Ref[Tensor(F32)][7, 4096], UMonadNoShape)    # fg_268=▸Load.268 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#▲[CNode]269
    %141 : $(▸5_WithLossCell.37):Tensor(F32)[7, 4096] = Primitive::TupleGetItem{prim_type=1}(%140, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((7, 4096), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]270
    %142 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape) = FuncGraph::fg_271(%139, %141)    #(Tensor(F32)[8, 4096], Tensor(F32)[7, 4096])    # fg_271=▸MatMul.271 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:468/        x = self.matmul(x, self.weight)/#▲x
    %143 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%142, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]272
    %144 : $(▸5_WithLossCell.37):Tensor(F32)[8, 7] = Primitive::TupleGetItem{prim_type=1}(%142, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]273
    %145 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((7), NoShape) = FuncGraph::fg_274(%para21, %para-1)    #(Ref[Tensor(F32)][7], UMonadNoShape)    # fg_274=▸Load.274 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#▲[CNode]275
    %146 : $(▸5_WithLossCell.37):Tensor(F32)[7] = Primitive::TupleGetItem{prim_type=1}(%145, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((7), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]276
    %147 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape) = FuncGraph::fg_277(%144, %146)    #(Tensor(F32)[8, 7], Tensor(F32)[7])    # fg_277=▸BiasAdd.277 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:470/            x = self.bias_add(x, self.bias)/#▲x
    %148 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%147, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]278
    %149 : $(▸5_WithLossCell.37):Tensor(F32)[8, 7] = Primitive::TupleGetItem{prim_type=1}(%147, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((8, 7), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]279
    %150 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((), NoShape) = FuncGraph::fg_280(%149, %para-1)    #(Tensor(F32)[8, 7], Tensor(I32)[8])    # fg_280=▸SparseSoftmaxCrossEntropyWithLogits.280 #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:676/                x = self.sparse_softmax_cross_entropy(logits, labels)/#▲x
    %151 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%150, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]281
    %152 : $(▸5_WithLossCell.37):Tensor(F32)[] = Primitive::TupleGetItem{prim_type=1}(%150, I64(0))    #(Tuple[Tensor(F32),Func]TupleShape((), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]282
    %153 : $(▸5_WithLossCell.37):Tuple[Tuple[Tensor(F32)*19],Func]TupleShape(TupleShape((7, 4096), (4096, 4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (128, 128, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (128, 64, 3, 3), (256, 128, 3, 3), (256, 256, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (4096), (4096), (7)), NoShape) = MakeTupleGradient::make_tuple_gradient(%141, %122, %103, %81, %66, %54, %40, %26, %12, %6, %20, %34, %46, %60, %73, %89, %108, %127, %146)    #(Tensor(F32)[7, 4096], Tensor(F32)[4096, 4096], Tensor(F32)[4096, 512], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 256, 3, 3], Tensor(F32)[256, 256, 3, 3], Tensor(F32)[128, 128, 3, 3], Tensor(F32)[64, 64, 3, 3], Tensor(F32)[64, 3, 3, 3], Tensor(F32)[128, 64, 3, 3], Tensor(F32)[256, 128, 3, 3], Tensor(F32)[256, 256, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[512, 512, 3, 3], Tensor(F32)[4096], Tensor(F32)[4096], Tensor(F32)[7]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#▲[CNode]283
    %154 : $(▸5_WithLossCell.37):Tuple[Tensor(F32)*19]TupleShape((7, 4096), (4096, 4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (128, 128, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (128, 64, 3, 3), (256, 128, 3, 3), (256, 256, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (4096), (4096), (7)) = Primitive::TupleGetItem{prim_type=1}(%153, I64(0))    #(Tuple[Tuple[Tensor(F32)*19],Func]TupleShape(TupleShape((7, 4096), (4096, 4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (128, 128, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (128, 64, 3, 3), (256, 128, 3, 3), (256, 256, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (4096), (4096), (7)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]284
    %155 : $(▸5_WithLossCell.37):Tuple[UMonad,Func]TupleShape(NoShape, NoShape) = FuncGraph::fg_285(%para-1, %154)    #(UMonadNoShape, Tuple[Tensor(F32)*19]TupleShape((7, 4096), (4096, 4096), (4096, 512), (512, 512, 3, 3), (512, 512, 3, 3), (512, 256, 3, 3), (256, 256, 3, 3), (128, 128, 3, 3), (64, 64, 3, 3), (64, 3, 3, 3), (128, 64, 3, 3), (256, 128, 3, 3), (256, 256, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (512, 512, 3, 3), (4096), (4096), (7)))    # fg_285=▸UpdateState.285 #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#▲[CNode]286
    %156 : $(▸5_WithLossCell.37):UMonadNoShape = Primitive::TupleGetItem{prim_type=1}(%155, I64(0))    #(Tuple[UMonad,Func]TupleShape(NoShape, NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]287
    %157 : $(▸5_WithLossCell.37):Tuple[Tensor(F32),Func]TupleShape((), NoShape) = FuncGraph::fg_288(%152, %156)    #(Tensor(F32)[], UMonadNoShape)    # fg_288=▸Depend.288 #scope: Default
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/nn/wrap/cell_wrapper.py:118/        return self._loss_fn(out, label)/#▲[CNode]289
    %158 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%157, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((), NoShape), I64NoShape) #scope: Default
#[CNode]290
    %159 : Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (), NoShape) = %158(%para83)    #(Tensor(F32)[]) #scope: Default
#[CNode]291
    %160 : Tensor(F32)[] = Primitive::TupleGetItem{prim_type=1}(%159, I64(1))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (), NoShape), I64NoShape) #scope: Default
#[CNode]292
    %161 : Tensor(F32)[] = Primitive::RealInner{prim_type=1}(%160)    #(Tensor(F32)[]) #scope: Default
#[CNode]293
    %162 : Tuple[EnvType,Tensor(F32),Tensor(I32)]TupleShape(NoShape, (8, 7), (8)) = %151(%161)    #(Tensor(F32)[]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]294
    %163 : Tensor(F32)[8, 7] = Primitive::TupleGetItem{prim_type=1}(%162, I64(1))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)]TupleShape(NoShape, (8, 7), (8)), I64NoShape) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]295
    %164 : Tensor(F32)[8, 7] = Primitive::RealInner{prim_type=1}(%163)    #(Tensor(F32)[8, 7]) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]296
    %165 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 7), (7)) = %148(%164)    #(Tensor(F32)[8, 7]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]297
    %166 : Tensor(F32)[8, 7] = Primitive::TupleGetItem{prim_type=1}(%165, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 7), (7)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]298
    %167 : Tensor(F32)[8, 7] = Primitive::RealInner{prim_type=1}(%166)    #(Tensor(F32)[8, 7]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]299
    %168 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (7, 4096)) = %143(%167)    #(Tensor(F32)[8, 7]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]300
    %169 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%168, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (7, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]301
    %170 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%169)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]302
    %171 : Tuple[EnvType,Tuple[Tensor(F32)*2],I64]TupleShape(NoShape, TupleShape((8, 4096), (8, 4096)), NoShape) = %138(%170)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]303
    %172 : Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)) = Primitive::TupleGetItem{prim_type=1}(%171, I64(1))    #(Tuple[EnvType,Tuple[Tensor(F32)*2],I64]TupleShape(NoShape, TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]304
    %173 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)) = %135(%172)    #(Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096))) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]305
    %174 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%173, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]306
    %175 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%174)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/5-Dropout
#[CNode]307
    %176 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)) = %132(%175)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
#[CNode]308
    %177 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%176, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
#[CNode]309
    %178 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%177)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/4-ReLU
#[CNode]310
    %179 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)) = %129(%178)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]311
    %180 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%179, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]312
    %181 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%180)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]313
    %182 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096, 4096)) = %124(%181)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]314
    %183 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%182, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]315
    %184 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%183)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]316
    %185 : Tuple[EnvType,Tuple[Tensor(F32)*2],I64]TupleShape(NoShape, TupleShape((8, 4096), (8, 4096)), NoShape) = %119(%184)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]317
    %186 : Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096)) = Primitive::TupleGetItem{prim_type=1}(%185, I64(1))    #(Tuple[EnvType,Tuple[Tensor(F32)*2],I64]TupleShape(NoShape, TupleShape((8, 4096), (8, 4096)), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]318
    %187 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)) = %116(%186)    #(Tuple[Tensor(F32)*2]TupleShape((8, 4096), (8, 4096))) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]319
    %188 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%187, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]320
    %189 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%188)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/2-Dropout
#[CNode]321
    %190 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)) = %113(%189)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
#[CNode]322
    %191 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%190, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
#[CNode]323
    %192 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%191)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/1-ReLU
#[CNode]324
    %193 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)) = %110(%192)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]325
    %194 : Tensor(F32)[8, 4096] = Primitive::TupleGetItem{prim_type=1}(%193, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]326
    %195 : Tensor(F32)[8, 4096] = Primitive::RealInner{prim_type=1}(%194)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]327
    %196 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512), (4096, 512)) = %105(%195)    #(Tensor(F32)[8, 4096]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]328
    %197 : Tensor(F32)[8, 512] = Primitive::TupleGetItem{prim_type=1}(%196, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512), (4096, 512)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]329
    %198 : Tensor(F32)[8, 512] = Primitive::RealInner{prim_type=1}(%197)    #(Tensor(F32)[8, 512]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]330
    %199 : Tuple[EnvType,Tensor(F32),Tuple[I64*2]]TupleShape(NoShape, (8, 512, 1, 1), TupleShape(NoShape, NoShape)) = %100(%198)    #(Tensor(F32)[8, 512]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
#[CNode]331
    %200 : Tensor(F32)[8, 512, 1, 1] = Primitive::TupleGetItem{prim_type=1}(%199, I64(1))    #(Tuple[EnvType,Tensor(F32),Tuple[I64*2]]TupleShape(NoShape, (8, 512, 1, 1), TupleShape(NoShape, NoShape)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
#[CNode]332
    %201 : Tensor(F32)[8, 512, 1, 1] = Primitive::RealInner{prim_type=1}(%200)    #(Tensor(F32)[8, 512, 1, 1]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet
#[CNode]333
    %202 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)) = %97(%201)    #(Tensor(F32)[8, 512, 1, 1]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
#[CNode]334
    %203 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%202, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
#[CNode]335
    %204 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%203)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/6-MaxPool2d
#[CNode]336
    %205 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)) = %94(%204)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
#[CNode]337
    %206 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%205, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
#[CNode]338
    %207 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%206)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/5-ReLU
#[CNode]339
    %208 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)) = %91(%207)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]340
    %209 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%208, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]341
    %210 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%209)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]342
    %211 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)) = %86(%210)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
#[CNode]343
    %212 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%211, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
#[CNode]344
    %213 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%212)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/3-ReLU
#[CNode]345
    %214 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)) = %83(%213)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]346
    %215 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%214, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]347
    %216 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%215)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]348
    %217 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)) = %78(%216)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
#[CNode]349
    %218 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%217, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 2, 2)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
#[CNode]350
    %219 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%218)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/1-ReLU
#[CNode]351
    %220 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)) = %75(%219)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]352
    %221 : Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%220, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]353
    %222 : Tensor(F32)[512, 512, 3, 3] = Primitive::RealInner{prim_type=1}(%221)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]354
    %223 : Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 512, 3, 3), NoShape) = %4(%222)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]355
    %224 : Tensor(F32)[512, 512, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%223, I64(1))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 512, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]356
    %225 : Tensor(F32)[512, 512, 3, 3] = Primitive::RealInner{prim_type=1}(%224)    #(Tensor(F32)[512, 512, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]357
    %226 : EnvTypeNoShape = Primitive::EnvironSet{prim_type=1}(%1, %2, %225)    #(EnvTypeNoShape, SymTypeNoShape, Tensor(F32)[512, 512, 3, 3]) #scope: Default
#[CNode]358
    %227 : SymTypeNoShape = Primitive::embed{prim_type=1}(%para10)    #(Ref[Tensor(F32)][512, 256, 3, 3]) #scope: Default
#[CNode]359
    %228 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%53, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 256, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]360
    %229 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%55, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]361
    %230 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%57, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
#[CNode]362
    %231 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%61, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]363
    %232 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%63, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
#[CNode]364
    %233 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%67, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]365
    %234 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%69, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
#[CNode]366
    %235 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%71, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 512, 2, 2), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
#[CNode]367
    %236 : Tensor(F32)[8, 512, 2, 2] = Primitive::TupleGetItem{prim_type=1}(%220, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]368
    %237 : Tensor(F32)[8, 512, 2, 2] = Primitive::RealInner{prim_type=1}(%236)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]369
    %238 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)) = %235(%237)    #(Tensor(F32)[8, 512, 2, 2]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
#[CNode]370
    %239 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%238, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
#[CNode]371
    %240 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%239)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/6-MaxPool2d
#[CNode]372
    %241 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)) = %234(%240)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
#[CNode]373
    %242 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%241, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
#[CNode]374
    %243 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%242)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/5-ReLU
#[CNode]375
    %244 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)) = %233(%243)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]376
    %245 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%244, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]377
    %246 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%245)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]378
    %247 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)) = %232(%246)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
#[CNode]379
    %248 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%247, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
#[CNode]380
    %249 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%248)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/3-ReLU
#[CNode]381
    %250 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)) = %231(%249)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]382
    %251 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%250, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]383
    %252 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%251)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]384
    %253 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)) = %230(%252)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
#[CNode]385
    %254 : Tensor(F32)[8, 512, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%253, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 512, 4, 4)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
#[CNode]386
    %255 : Tensor(F32)[8, 512, 4, 4] = Primitive::RealInner{prim_type=1}(%254)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/1-ReLU
#[CNode]387
    %256 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 4, 4), (512, 256, 3, 3)) = %229(%255)    #(Tensor(F32)[8, 512, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]388
    %257 : Tensor(F32)[512, 256, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%256, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 4, 4), (512, 256, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]389
    %258 : Tensor(F32)[512, 256, 3, 3] = Primitive::RealInner{prim_type=1}(%257)    #(Tensor(F32)[512, 256, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]390
    %259 : Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 256, 3, 3), NoShape) = %228(%258)    #(Tensor(F32)[512, 256, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]391
    %260 : Tensor(F32)[512, 256, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%259, I64(1))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 256, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]392
    %261 : Tensor(F32)[512, 256, 3, 3] = Primitive::RealInner{prim_type=1}(%260)    #(Tensor(F32)[512, 256, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]393
    %262 : EnvTypeNoShape = Primitive::EnvironSet{prim_type=1}(%226, %227, %261)    #(EnvTypeNoShape, SymTypeNoShape, Tensor(F32)[512, 256, 3, 3]) #scope: Default
#[CNode]394
    %263 : SymTypeNoShape = Primitive::embed{prim_type=1}(%para7)    #(Ref[Tensor(F32)][256, 128, 3, 3]) #scope: Default
#[CNode]395
    %264 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%33, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((256, 128, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]396
    %265 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%35, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]397
    %266 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%37, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
#[CNode]398
    %267 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%41, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]399
    %268 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%43, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
#[CNode]400
    %269 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%47, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]401
    %270 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%49, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
#[CNode]402
    %271 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%51, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 256, 4, 4), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
#[CNode]403
    %272 : Tensor(F32)[8, 256, 4, 4] = Primitive::TupleGetItem{prim_type=1}(%256, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 4, 4), (512, 256, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]404
    %273 : Tensor(F32)[8, 256, 4, 4] = Primitive::RealInner{prim_type=1}(%272)    #(Tensor(F32)[8, 256, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell/0-Conv2d
#[CNode]405
    %274 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)) = %271(%273)    #(Tensor(F32)[8, 256, 4, 4]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
#[CNode]406
    %275 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%274, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
#[CNode]407
    %276 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%275)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/6-MaxPool2d
#[CNode]408
    %277 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)) = %270(%276)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
#[CNode]409
    %278 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%277, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
#[CNode]410
    %279 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%278)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/5-ReLU
#[CNode]411
    %280 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)) = %269(%279)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]412
    %281 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%280, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]413
    %282 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%281)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]414
    %283 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)) = %268(%282)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
#[CNode]415
    %284 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%283, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
#[CNode]416
    %285 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%284)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/3-ReLU
#[CNode]417
    %286 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)) = %267(%285)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]418
    %287 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%286, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]419
    %288 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%287)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]420
    %289 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)) = %266(%288)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
#[CNode]421
    %290 : Tensor(F32)[8, 256, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%289, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 256, 8, 8)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
#[CNode]422
    %291 : Tensor(F32)[8, 256, 8, 8] = Primitive::RealInner{prim_type=1}(%290)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/1-ReLU
#[CNode]423
    %292 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 8, 8), (256, 128, 3, 3)) = %265(%291)    #(Tensor(F32)[8, 256, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]424
    %293 : Tensor(F32)[256, 128, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%292, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 8, 8), (256, 128, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]425
    %294 : Tensor(F32)[256, 128, 3, 3] = Primitive::RealInner{prim_type=1}(%293)    #(Tensor(F32)[256, 128, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]426
    %295 : Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (256, 128, 3, 3), NoShape) = %264(%294)    #(Tensor(F32)[256, 128, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]427
    %296 : Tensor(F32)[256, 128, 3, 3] = Primitive::TupleGetItem{prim_type=1}(%295, I64(1))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (256, 128, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]428
    %297 : Tensor(F32)[256, 128, 3, 3] = Primitive::RealInner{prim_type=1}(%296)    #(Tensor(F32)[256, 128, 3, 3]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]429
    %298 : EnvTypeNoShape = Primitive::EnvironSet{prim_type=1}(%262, %263, %297)    #(EnvTypeNoShape, SymTypeNoShape, Tensor(F32)[256, 128, 3, 3]) #scope: Default
#[CNode]430
    %299 : SymTypeNoShape = Primitive::embed{prim_type=1}(%para5)    #(Ref[Tensor(F32)][128, 64, 3, 3]) #scope: Default
#[CNode]431
    %300 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%19, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((128, 64, 3, 3), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]432
    %301 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%21, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]433
    %302 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%23, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
#[CNode]434
    %303 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%27, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]435
    %304 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%29, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 16, 16), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
#[CNode]436
    %305 : $(▸5_WithLossCell.37):FuncNoShape = Primitive::TupleGetItem{prim_type=1}(%31, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 128, 8, 8), NoShape), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
#[CNode]437
    %306 : Tensor(F32)[8, 128, 8, 8] = Primitive::TupleGetItem{prim_type=1}(%292, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 8, 8), (256, 128, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]438
    %307 : Tensor(F32)[8, 128, 8, 8] = Primitive::RealInner{prim_type=1}(%306)    #(Tensor(F32)[8, 128, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/0-Conv2d
#[CNode]439
    %308 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)) = %305(%307)    #(Tensor(F32)[8, 128, 8, 8]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
#[CNode]440
    %309 : Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%308, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
#[CNode]441
    %310 : Tensor(F32)[8, 128, 16, 16] = Primitive::RealInner{prim_type=1}(%309)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/4-MaxPool2d
#[CNode]442
    %311 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)) = %304(%310)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
#[CNode]443
    %312 : Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%311, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
#[CNode]444
    %313 : Tensor(F32)[8, 128, 16, 16] = Primitive::RealInner{prim_type=1}(%312)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/3-ReLU
#[CNode]445
    %314 : Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 16, 16), (128, 128, 3, 3)) = %303(%313)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]446
    %315 : Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%314, I64(1))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 16, 16), (128, 128, 3, 3)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]447
    %316 : Tensor(F32)[8, 128, 16, 16] = Primitive::RealInner{prim_type=1}(%315)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]448
    %317 : Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)) = %302(%316)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
#[CNode]449
    %318 : Tensor(F32)[8, 128, 16, 16] = Primitive::TupleGetItem{prim_type=1}(%317, I64(1))    #(Tuple[EnvType,Tensor(F32)]TupleShape(NoShape, (8, 128, 16, 16)), I64NoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
#[CNode]450
    %319 : Tensor(F32)[8, 128, 16, 16] = Primitive::RealInner{prim_type=1}(%318)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/1-ReLU
#[CNode]451

#------------------------> 1
    %320 = %301(%319)    #(Tensor(F32)[8, 128, 16, 16]) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]452
    %321 = Primitive::TupleGetItem{prim_type=1}(%320, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]453
    %322 = Primitive::RealInner{prim_type=1}(%321)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]454
    %323 = %300(%322)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]455
    %324 = Primitive::TupleGetItem{prim_type=1}(%323, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]456
    %325 = Primitive::RealInner{prim_type=1}(%324)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]457
    %326 = Primitive::EnvironSet{prim_type=1}(%298, %299, %325)    #(EnvTypeNoShape, SymTypeNoShape, Undefined) #scope: Default
#[CNode]458
    %327 = Primitive::embed{prim_type=1}(%para16)    #(Ref[Tensor(F32)][4096, 512]) #scope: Default
#[CNode]459
    %328 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%102, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((4096, 512), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]460
    %329 = Primitive::TupleGetItem{prim_type=1}(%196, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512), (4096, 512)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]461
    %330 = Primitive::RealInner{prim_type=1}(%329)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]462
    %331 = %328(%330)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]463
    %332 = Primitive::TupleGetItem{prim_type=1}(%331, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]464
    %333 = Primitive::RealInner{prim_type=1}(%332)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]465
    %334 = Primitive::EnvironSet{prim_type=1}(%326, %327, %333)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]466
    %335 = Primitive::embed{prim_type=1}(%para17)    #(Ref[Tensor(F32)][4096]) #scope: Default
#[CNode]467
    %336 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%107, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((4096), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]468
    %337 = Primitive::TupleGetItem{prim_type=1}(%193, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]469
    %338 = Primitive::RealInner{prim_type=1}(%337)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]470
    %339 = %336(%338)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]471
    %340 = Primitive::TupleGetItem{prim_type=1}(%339, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]472
    %341 = Primitive::RealInner{prim_type=1}(%340)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]473
    %342 = Primitive::EnvironSet{prim_type=1}(%334, %335, %341)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]474
    %343 = Primitive::embed{prim_type=1}(%para3)    #(Ref[Tensor(F32)][64, 3, 3, 3]) #scope: Default
#[CNode]475
    %344 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%5, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((64, 3, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]476
    %345 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%7, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]477
    %346 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%9, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
#[CNode]478
    %347 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%13, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]479
    %348 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%15, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 32, 32), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
#[CNode]480
    %349 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%17, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((8, 64, 16, 16), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
#[CNode]481
    %350 = Primitive::TupleGetItem{prim_type=1}(%320, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]482
    %351 = Primitive::RealInner{prim_type=1}(%350)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#[CNode]483
    %352 = %349(%351)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
#[CNode]484
    %353 = Primitive::TupleGetItem{prim_type=1}(%352, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
#[CNode]485
    %354 = Primitive::RealInner{prim_type=1}(%353)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/4-MaxPool2d
#[CNode]486
    %355 = %348(%354)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
#[CNode]487
    %356 = Primitive::TupleGetItem{prim_type=1}(%355, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
#[CNode]488
    %357 = Primitive::RealInner{prim_type=1}(%356)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/3-ReLU
#[CNode]489
    %358 = %347(%357)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]490
    %359 = Primitive::TupleGetItem{prim_type=1}(%358, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]491
    %360 = Primitive::RealInner{prim_type=1}(%359)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]492
    %361 = %346(%360)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
#[CNode]493
    %362 = Primitive::TupleGetItem{prim_type=1}(%361, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
#[CNode]494
    %363 = Primitive::RealInner{prim_type=1}(%362)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/1-ReLU
#[CNode]495
    %364 = %345(%363)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]496
    %365 = Primitive::TupleGetItem{prim_type=1}(%364, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]497
    %366 = Primitive::RealInner{prim_type=1}(%365)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]498
    %367 = %344(%366)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]499
    %368 = Primitive::TupleGetItem{prim_type=1}(%367, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]500
    %369 = Primitive::RealInner{prim_type=1}(%368)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]501
    %370 = Primitive::EnvironSet{prim_type=1}(%342, %343, %369)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]502
    %371 = Primitive::embed{prim_type=1}(%para14)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]503
    %372 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%80, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]504
    %373 = Primitive::TupleGetItem{prim_type=1}(%214, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]505
    %374 = Primitive::RealInner{prim_type=1}(%373)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]506
    %375 = %372(%374)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]507
    %376 = Primitive::TupleGetItem{prim_type=1}(%375, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]508
    %377 = Primitive::RealInner{prim_type=1}(%376)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]509
    %378 = Primitive::EnvironSet{prim_type=1}(%370, %371, %377)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]510
    %379 = Primitive::embed{prim_type=1}(%para4)    #(Ref[Tensor(F32)][64, 64, 3, 3]) #scope: Default
#[CNode]511
    %380 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%11, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((64, 64, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]512
    %381 = Primitive::TupleGetItem{prim_type=1}(%358, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]513
    %382 = Primitive::RealInner{prim_type=1}(%381)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/2-Conv2d
#[CNode]514
    %383 = %380(%382)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]515
    %384 = Primitive::TupleGetItem{prim_type=1}(%383, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]516
    %385 = Primitive::RealInner{prim_type=1}(%384)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]517
    %386 = Primitive::EnvironSet{prim_type=1}(%378, %379, %385)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]518
    %387 = Primitive::embed{prim_type=1}(%para11)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]519
    %388 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%59, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]520
    %389 = Primitive::TupleGetItem{prim_type=1}(%250, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]521
    %390 = Primitive::RealInner{prim_type=1}(%389)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]522
    %391 = %388(%390)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]523
    %392 = Primitive::TupleGetItem{prim_type=1}(%391, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]524
    %393 = Primitive::RealInner{prim_type=1}(%392)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]525
    %394 = Primitive::EnvironSet{prim_type=1}(%386, %387, %393)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]526
    %395 = Primitive::embed{prim_type=1}(%para19)    #(Ref[Tensor(F32)][4096]) #scope: Default
#[CNode]527
    %396 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%126, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((4096), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]528
    %397 = Primitive::TupleGetItem{prim_type=1}(%179, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]529
    %398 = Primitive::RealInner{prim_type=1}(%397)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]530
    %399 = %396(%398)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]531
    %400 = Primitive::TupleGetItem{prim_type=1}(%399, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]532
    %401 = Primitive::RealInner{prim_type=1}(%400)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]533
    %402 = Primitive::EnvironSet{prim_type=1}(%394, %395, %401)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]534
    %403 = Primitive::embed{prim_type=1}(%para18)    #(Ref[Tensor(F32)][4096, 4096]) #scope: Default
#[CNode]535
    %404 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%121, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((4096, 4096), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]536
    %405 = Primitive::TupleGetItem{prim_type=1}(%182, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (4096, 4096)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]537
    %406 = Primitive::RealInner{prim_type=1}(%405)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]538
    %407 = %404(%406)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]539
    %408 = Primitive::TupleGetItem{prim_type=1}(%407, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]540
    %409 = Primitive::RealInner{prim_type=1}(%408)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]541
    %410 = Primitive::EnvironSet{prim_type=1}(%402, %403, %409)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]542
    %411 = Primitive::embed{prim_type=1}(%para6)    #(Ref[Tensor(F32)][128, 128, 3, 3]) #scope: Default
#[CNode]543
    %412 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%25, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((128, 128, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]544
    %413 = Primitive::TupleGetItem{prim_type=1}(%314, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 128, 16, 16), (128, 128, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]545
    %414 = Primitive::RealInner{prim_type=1}(%413)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/2-Conv2d
#[CNode]546
    %415 = %412(%414)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]547
    %416 = Primitive::TupleGetItem{prim_type=1}(%415, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]548
    %417 = Primitive::RealInner{prim_type=1}(%416)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]549
    %418 = Primitive::EnvironSet{prim_type=1}(%410, %411, %417)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]550
    %419 = Primitive::embed{prim_type=1}(%para8)    #(Ref[Tensor(F32)][256, 256, 3, 3]) #scope: Default
#[CNode]551
    %420 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%39, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]552
    %421 = Primitive::TupleGetItem{prim_type=1}(%286, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]553
    %422 = Primitive::RealInner{prim_type=1}(%421)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]554
    %423 = %420(%422)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]555
    %424 = Primitive::TupleGetItem{prim_type=1}(%423, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]556
    %425 = Primitive::RealInner{prim_type=1}(%424)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]557
    %426 = Primitive::EnvironSet{prim_type=1}(%418, %419, %425)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]558
    %427 = Primitive::embed{prim_type=1}(%para15)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]559
    %428 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%88, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]560
    %429 = Primitive::TupleGetItem{prim_type=1}(%208, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 2, 2), (512, 512, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]561
    %430 = Primitive::RealInner{prim_type=1}(%429)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]562
    %431 = %428(%430)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]563
    %432 = Primitive::TupleGetItem{prim_type=1}(%431, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]564
    %433 = Primitive::RealInner{prim_type=1}(%432)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]565
    %434 = Primitive::EnvironSet{prim_type=1}(%426, %427, %433)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]566
    %435 = Primitive::embed{prim_type=1}(%para12)    #(Ref[Tensor(F32)][512, 512, 3, 3]) #scope: Default
#[CNode]567
    %436 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%65, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((512, 512, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]568
    %437 = Primitive::TupleGetItem{prim_type=1}(%244, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 512, 4, 4), (512, 512, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]569
    %438 = Primitive::RealInner{prim_type=1}(%437)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell/0-Conv2d
#[CNode]570
    %439 = %436(%438)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]571
    %440 = Primitive::TupleGetItem{prim_type=1}(%439, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]572
    %441 = Primitive::RealInner{prim_type=1}(%440)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]573
    %442 = Primitive::EnvironSet{prim_type=1}(%434, %435, %441)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]574
    %443 = Primitive::embed{prim_type=1}(%para9)    #(Ref[Tensor(F32)][256, 256, 3, 3]) #scope: Default
#[CNode]575
    %444 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%45, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((256, 256, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]576
    %445 = Primitive::TupleGetItem{prim_type=1}(%280, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 256, 8, 8), (256, 256, 3, 3)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]577
    %446 = Primitive::RealInner{prim_type=1}(%445)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell/2-Conv2d
#[CNode]578
    %447 = %444(%446)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]579
    %448 = Primitive::TupleGetItem{prim_type=1}(%447, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]580
    %449 = Primitive::RealInner{prim_type=1}(%448)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]581
    %450 = Primitive::EnvironSet{prim_type=1}(%442, %443, %449)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]582
    %451 = Primitive::embed{prim_type=1}(%para20)    #(Ref[Tensor(F32)][7, 4096]) #scope: Default
#[CNode]583
    %452 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%140, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((7, 4096), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]584
    %453 = Primitive::TupleGetItem{prim_type=1}(%168, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 4096), (7, 4096)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]585
    %454 = Primitive::RealInner{prim_type=1}(%453)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]586
    %455 = %452(%454)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]587
    %456 = Primitive::TupleGetItem{prim_type=1}(%455, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]588
    %457 = Primitive::RealInner{prim_type=1}(%456)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]589
    %458 = Primitive::EnvironSet{prim_type=1}(%450, %451, %457)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]590
    %459 = Primitive::embed{prim_type=1}(%para21)    #(Ref[Tensor(F32)][7]) #scope: Default
#[CNode]591
    %460 = $(▸5_WithLossCell.37):Primitive::TupleGetItem{prim_type=1}(%145, I64(1))    #(Tuple[Tensor(F32),Func]TupleShape((7), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]592
    %461 = Primitive::TupleGetItem{prim_type=1}(%165, I64(2))    #(Tuple[EnvType,Tensor(F32)*2]TupleShape(NoShape, (8, 7), (7)), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]593
    %462 = Primitive::RealInner{prim_type=1}(%461)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]594
    %463 = %460(%462)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]595
    %464 = Primitive::TupleGetItem{prim_type=1}(%463, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]596
    %465 = Primitive::RealInner{prim_type=1}(%464)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]597
    %466 = Primitive::EnvironSet{prim_type=1}(%458, %459, %465)    #(Undefined, Undefined, Undefined) #scope: Default
#[CNode]598
    %467 = Primitive::TupleGetItem{prim_type=1}(%364, I64(1))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]599
    %468 = Primitive::RealInner{prim_type=1}(%467)    #(Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell/0-Conv2d
#[CNode]600
    %469 = Primitive::TupleGetItem{prim_type=1}(%162, I64(2))    #(Tuple[EnvType,Tensor(F32),Tensor(I32)]TupleShape(NoShape, (8, 7), (8)), Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]601
    %470 = Primitive::RealInner{prim_type=1}(%469)    #(Undefined) #scope: Default/network-WithLossCell/_loss_fn-SoftmaxCrossEntropyWithLogits
#[CNode]602
    %471 = Primitive::TupleGetItem{prim_type=1}(%367, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]603
    %472 = Primitive::TupleGetItem{prim_type=1}(%383, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv1-SequentialCell
#[CNode]604
    %473 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%471, %472)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]605
    %474 = Primitive::TupleGetItem{prim_type=1}(%323, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]606
    %475 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%473, %474)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]607
    %476 = Primitive::TupleGetItem{prim_type=1}(%415, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell
#[CNode]608
    %477 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%475, %476)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]609
    %478 = Primitive::TupleGetItem{prim_type=1}(%295, I64(2))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (256, 128, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]610
    %479 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%477, %478)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]611
    %480 = Primitive::TupleGetItem{prim_type=1}(%423, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]612
    %481 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%479, %480)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]613
    %482 = Primitive::TupleGetItem{prim_type=1}(%447, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv3-SequentialCell
#[CNode]614
    %483 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%481, %482)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]615
    %484 = Primitive::TupleGetItem{prim_type=1}(%259, I64(2))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 256, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]616
    %485 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%483, %484)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]617
    %486 = Primitive::TupleGetItem{prim_type=1}(%391, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]618
    %487 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%485, %486)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]619
    %488 = Primitive::TupleGetItem{prim_type=1}(%439, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv4-SequentialCell
#[CNode]620
    %489 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%487, %488)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]621
    %490 = Primitive::TupleGetItem{prim_type=1}(%223, I64(2))    #(Tuple[EnvType,Tensor(F32),UMonad]TupleShape(NoShape, (512, 512, 3, 3), NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]622
    %491 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%489, %490)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]623
    %492 = Primitive::TupleGetItem{prim_type=1}(%375, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]624
    %493 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%491, %492)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]625
    %494 = Primitive::TupleGetItem{prim_type=1}(%431, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv5-SequentialCell
#[CNode]626
    %495 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%493, %494)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]627
    %496 = Primitive::TupleGetItem{prim_type=1}(%331, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]628
    %497 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%495, %496)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]629
    %498 = Primitive::TupleGetItem{prim_type=1}(%339, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]630
    %499 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%497, %498)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]631
    %500 = Primitive::TupleGetItem{prim_type=1}(%407, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]632
    %501 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%499, %500)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]633
    %502 = Primitive::TupleGetItem{prim_type=1}(%399, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]634
    %503 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%501, %502)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]635
    %504 = Primitive::TupleGetItem{prim_type=1}(%455, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell
#[CNode]636
    %505 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%503, %504)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]637
    %506 = Primitive::TupleGetItem{prim_type=1}(%463, I64(2))    #(Undefined, Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/fc-SequentialCell/0-Dense
#[CNode]638
    %507 = HyperMapPy::hyper_map[add_backward]{fn_leaf=MultitypeFuncGraph::add_backward{(Tuple, CSRTensor), (CSRTensor, Tuple), (RowTensor, Tensor), (IOMonad, IOMonad), (NoneType, NoneType), (UMonad, UMonad), (COOTensor, Tuple), (COOTensor, COOTensor), (Tensor, Tensor), (CSRTensor, CSRTensor), (EnvType, EnvType), (Tuple, COOTensor), (Number, Number)}}(%505, %506)    #(Undefined, Undefined) #scope: Gradients/Default
#[CNode]639
    %508 = Primitive::MakeTuple{prim_type=1}(%466, %468, %470, %507)    #(Undefined, Undefined, Undefined, Undefined) #scope: Default
#[CNode]640
    Primitive::Return{prim_type=1}(%508)    #(Undefined) #scope: Default
#[CNode]641
}
# order:
#   1: @◂5_WithLossCell.34:[CNode]642{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]643}
#   2: @◂5_WithLossCell.34:[CNode]644{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]287}
#   3: @◂5_WithLossCell.34:[CNode]645{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]284}
#   4: @◂5_WithLossCell.34:[CNode]646{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]282}
#   5: @◂5_WithLossCell.34:[CNode]647{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]279}
#   6: @◂5_WithLossCell.34:[CNode]648{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]276}
#   7: @◂5_WithLossCell.34:[CNode]649{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]273}
#   8: @◂5_WithLossCell.34:[CNode]650{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]270}
#   9: @◂5_WithLossCell.34:[CNode]651{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]267}
#  10: @◂5_WithLossCell.34:[CNode]652{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]264}
#  11: @◂5_WithLossCell.34:[CNode]653{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]260}
#  12: @◂5_WithLossCell.34:[CNode]654{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]256}
#  13: @◂5_WithLossCell.34:[CNode]655{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]253}
#  14: @◂5_WithLossCell.34:[CNode]656{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]250}
#  15: @◂5_WithLossCell.34:[CNode]657{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]247}
#  16: @◂5_WithLossCell.34:[CNode]658{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]244}
#  17: @◂5_WithLossCell.34:[CNode]659{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]241}
#  18: @◂5_WithLossCell.34:[CNode]660{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]237}
#  19: @◂5_WithLossCell.34:[CNode]661{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]233}
#  20: @◂5_WithLossCell.34:[CNode]662{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]230}
#  21: @◂5_WithLossCell.34:[CNode]663{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]227}
#  22: @◂5_WithLossCell.34:[CNode]664{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]224}
#  23: @◂5_WithLossCell.34:[CNode]665{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]221}
#  24: @◂5_WithLossCell.34:[CNode]666{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]217}
#  25: @◂5_WithLossCell.34:[CNode]667{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]214}
#  26: @◂5_WithLossCell.34:[CNode]668{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]210}
#  27: @◂5_WithLossCell.34:[CNode]669{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]208}
#  28: @◂5_WithLossCell.34:[CNode]670{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]207}
#  29: @◂5_WithLossCell.34:[CNode]671{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]203}
#  30: @◂5_WithLossCell.34:[CNode]672{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]201}
#  31: @◂5_WithLossCell.34:[CNode]673{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]200}
#  32: @◂5_WithLossCell.34:[CNode]674{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]196}
#  33: @◂5_WithLossCell.34:[CNode]675{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]194}
#  34: @◂5_WithLossCell.34:[CNode]676{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]193}
#  35: @◂5_WithLossCell.34:[CNode]677{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]191}
#  36: @◂5_WithLossCell.34:[CNode]678{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]188}
#  37: @◂5_WithLossCell.34:[CNode]679{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]187}
#  38: @◂5_WithLossCell.34:[CNode]680{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]186}
#  39: @◂5_WithLossCell.34:[CNode]681{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]183}
#  40: @◂5_WithLossCell.34:[CNode]682{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]182}
#  41: @◂5_WithLossCell.34:[CNode]683{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]180}
#  42: @◂5_WithLossCell.34:[CNode]684{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]177}
#  43: @◂5_WithLossCell.34:[CNode]685{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]175}
#  44: @◂5_WithLossCell.34:[CNode]686{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]172}
#  45: @◂5_WithLossCell.34:[CNode]687{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]170}
#  46: @◂5_WithLossCell.34:[CNode]688{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]167}
#  47: @◂5_WithLossCell.34:[CNode]689{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]166}
#  48: @◂5_WithLossCell.34:[CNode]690{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]165}
#  49: @◂5_WithLossCell.34:[CNode]691{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]162}
#  50: @◂5_WithLossCell.34:[CNode]692{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]161}
#  51: @◂5_WithLossCell.34:[CNode]693{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]159}
#  52: @◂5_WithLossCell.34:[CNode]694{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]156}
#  53: @◂5_WithLossCell.34:[CNode]695{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]154}
#  54: @◂5_WithLossCell.34:[CNode]696{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]151}
#  55: @◂5_WithLossCell.34:[CNode]697{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]149}
#  56: @◂5_WithLossCell.34:[CNode]698{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]146}
#  57: @◂5_WithLossCell.34:[CNode]699{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]144}
#  58: @◂5_WithLossCell.34:[CNode]700{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]141}
#  59: @◂5_WithLossCell.34:[CNode]701{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]138}
#  60: @◂5_WithLossCell.34:[CNode]702{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]136}
#  61: @◂5_WithLossCell.34:[CNode]703{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]133}
#  62: @◂5_WithLossCell.34:[CNode]704{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]131}
#  63: @◂5_WithLossCell.34:[CNode]705{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]128}
#  64: @◂5_WithLossCell.34:[CNode]706{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]126}
#  65: @◂5_WithLossCell.34:[CNode]707{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]123}
#  66: @◂5_WithLossCell.34:[CNode]708{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]120}
#  67: @◂5_WithLossCell.34:[CNode]709{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: [CNode]118}
#  68: @◂5_WithLossCell.34:[CNode]710{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<MakeTupleGradient> make_tuple_gradient.711}
#  69: @◂5_WithLossCell.34:[CNode]712{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸UpdateState.285}
#  70: @◂5_WithLossCell.34:[CNode]713{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.168}
#  71: @◂5_WithLossCell.34:[CNode]714{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.189}
#  72: @◂5_WithLossCell.34:[CNode]715{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MaxPool.171}
#  73: @◂5_WithLossCell.34:[CNode]716{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.211}
#  74: @◂5_WithLossCell.34:[CNode]717{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MaxPool.192}
#  75: @◂5_WithLossCell.34:[CNode]718{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MaxPool.215}
#  76: @◂5_WithLossCell.34:[CNode]719{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.129}
#  77: @◂5_WithLossCell.34:[CNode]720{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.274}
#  78: @◂5_WithLossCell.34:[CNode]721{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸BiasAdd.277}
#  79: @◂5_WithLossCell.34:[CNode]722{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.268}
#  80: @◂5_WithLossCell.34:[CNode]723{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MatMul.271}
#  81: @◂5_WithLossCell.34:[CNode]724{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MaxPool.132}
#  82: @◂5_WithLossCell.34:[CNode]725{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MaxPool.150}
#  83: @◂5_WithLossCell.34:[CNode]726{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Dropout.261}
#  84: @◂5_WithLossCell.34:[CNode]727{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<Int64Imm> 0}
#  85: @◂5_WithLossCell.34:[CNode]728{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸TupleGetItem.265}
#  86: @◂5_WithLossCell.34:[CNode]729{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.147}
#  87: @◂5_WithLossCell.34:[CNode]730{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.23}
#  88: @◂5_WithLossCell.34:[CNode]731{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.22}
#  89: @◂5_WithLossCell.34:[CNode]732{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.142}
#  90: @◂5_WithLossCell.34:[CNode]733{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.145}
#  91: @◂5_WithLossCell.34:[CNode]734{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MatMul.248}
#  92: @◂5_WithLossCell.34:[CNode]735{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸BiasAdd.254}
#  93: @◂5_WithLossCell.34:[CNode]736{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.245}
#  94: @◂5_WithLossCell.34:[CNode]737{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.251}
#  95: @◂5_WithLossCell.34:[CNode]738{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.25}
#  96: @◂5_WithLossCell.34:[CNode]739{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.24}
#  97: @◂5_WithLossCell.34:[CNode]740{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Dropout.238}
#  98: @◂5_WithLossCell.34:[CNode]741{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<Int64Imm> 0}
#  99: @◂5_WithLossCell.34:[CNode]742{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸TupleGetItem.242}
# 100: @◂5_WithLossCell.34:[CNode]743{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.124}
# 101: @◂5_WithLossCell.34:[CNode]744{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.127}
# 102: @◂5_WithLossCell.34:[CNode]745{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.121}
# 103: @◂5_WithLossCell.34:[CNode]746{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.116}
# 104: @◂5_WithLossCell.34:[CNode]747{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.119}
# 105: @◂5_WithLossCell.34:[CNode]748{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.228}
# 106: @◂5_WithLossCell.34:[CNode]749{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸BiasAdd.231}
# 107: @◂5_WithLossCell.34:[CNode]750{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.139}
# 108: @◂5_WithLossCell.34:[CNode]751{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.163}
# 109: @◂5_WithLossCell.34:[CNode]752{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.157}
# 110: @◂5_WithLossCell.34:[CNode]753{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.222}
# 111: @◂5_WithLossCell.34:[CNode]754{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸MatMul.225}
# 112: @◂5_WithLossCell.34:[CNode]755{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.184}
# 113: @◂5_WithLossCell.34:[CNode]756{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.178}
# 114: @◂5_WithLossCell.34:[CNode]757{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.134}
# 115: @◂5_WithLossCell.34:[CNode]758{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.137}
# 116: @◂5_WithLossCell.34:[CNode]759{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.204}
# 117: @◂5_WithLossCell.34:[CNode]760{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.197}
# 118: @◂5_WithLossCell.34:[CNode]761{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.152}
# 119: @◂5_WithLossCell.34:[CNode]762{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.155}
# 120: @◂5_WithLossCell.34:[CNode]763{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.257}
# 121: @◂5_WithLossCell.34:[CNode]764{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.26}
# 122: @◂5_WithLossCell.34:[CNode]765{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.27}
# 123: @◂5_WithLossCell.34:[CNode]766{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Load.173}
# 124: @◂5_WithLossCell.34:[CNode]767{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Conv2D.176}
# 125: @◂5_WithLossCell.34:[CNode]768{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸ReLU.234}
# 126: @◂5_WithLossCell.34:[CNode]769{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<ValueTuple> (8, -1)}
# 127: @◂5_WithLossCell.34:[CNode]770{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Reshape.218}
# 128: @◂5_WithLossCell.34:[CNode]771{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸SparseSoftmaxCrossEntropyWithLogits.280}
# 129: @◂5_WithLossCell.34:[CNode]772{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ValueNode<FuncGraph> ▸Depend.288}
# 130: @◂5_WithLossCell.34:[CNode]773{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ▸u}
# 131: @◂5_WithLossCell.34:[CNode]774{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ▸label}
# 132: @◂5_WithLossCell.34:[CNode]775{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: ▸data}
# 133: @◂5_WithLossCell.34:[CNode]776{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.6.bias}
# 134: @◂5_WithLossCell.34:[CNode]777{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.6.weight}
# 135: @◂5_WithLossCell.34:[CNode]778{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv3.4.weight}
# 136: @◂5_WithLossCell.34:[CNode]779{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv4.4.weight}
# 137: @◂5_WithLossCell.34:[CNode]780{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv5.4.weight}
# 138: @◂5_WithLossCell.34:[CNode]781{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv3.2.weight}
# 139: @◂5_WithLossCell.34:[CNode]782{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv2.2.weight}
# 140: @◂5_WithLossCell.34:[CNode]783{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.3.weight}
# 141: @◂5_WithLossCell.34:[CNode]784{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.3.bias}
# 142: @◂5_WithLossCell.34:[CNode]785{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv4.2.weight}
# 143: @◂5_WithLossCell.34:[CNode]786{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv1.2.weight}
# 144: @◂5_WithLossCell.34:[CNode]787{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv5.2.weight}
# 145: @◂5_WithLossCell.34:[CNode]788{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv1.0.weight}
# 146: @◂5_WithLossCell.34:[CNode]789{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.0.bias}
# 147: @◂5_WithLossCell.34:[CNode]790{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: fc.0.weight}
# 148: @◂5_WithLossCell.34:[CNode]791{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv2.0.weight}
# 149: @◂5_WithLossCell.34:[CNode]792{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv3.0.weight}
# 150: @◂5_WithLossCell.34:[CNode]793{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv4.0.weight}
# 151: @◂5_WithLossCell.34:[CNode]794{[0]: ValueNode<HyperMapPy> hyper_map[zeros_like_leaf].28, [1]: conv5.0.weight}
# 152: @◂5_WithLossCell.34:[CNode]641{[0]: ValueNode<Primitive> Return, [1]: [CNode]640}


# [No.3] ◂Conv2D.36
# In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:119/    def bprop(x, w, out, dout):/
funcgraph fg_36[fg_137](
        %para84 : Tensor(F32)[8, 128, 16, 16]    # ▽out
    ) {
    %1 : EnvTypeNoShape = Primitive::EnvironCreate{prim_type=1}() #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#795
    %2 : Tuple[EnvType]TupleShape(NoShape) = Primitive::MakeTuple{prim_type=1}(%1)    #(EnvTypeNoShape) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#796
    %3 : Tuple[I64*4]TupleShape(NoShape, NoShape, NoShape, NoShape) = DoSignaturePrimitive::S-Prim-Shape{prim_type=1}(%para-1)    #(Tensor(F32)[8, 64, 16, 16]) #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:120/        x_shape = get_shape(x)/#x_shape

#------------------------> 2
    %4 = DoSignaturePrimitive::S-Prim-is_shape_unknown{prim_type=1}(%3)    #(Tuple[I64*4]TupleShape(NoShape, NoShape, NoShape, NoShape)) #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:122/        if is_shape_unknown(x_shape):/#[CNode]797
    %5 = FuncGraph::fg_798(%4)    #(Undefined)    # fg_798=bool_.798 #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:122/        if is_shape_unknown(x_shape):/#[CNode]799
    %6 = Primitive::Switch{prim_type=1}(%5, FuncGraph::fg_800, FuncGraph::fg_801)    #(Undefined, Undefined, Undefined)    # fg_800=✓Conv2D.800, fg_801=✗Conv2D.801 #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:122/        if is_shape_unknown(x_shape):/#[CNode]802
    %7 = %6() #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:122/        if is_shape_unknown(x_shape):/#[CNode]803
    %8 = Primitive::TupleGetItem{prim_type=1}(%7, I64(0))    #(Undefined, I64NoShape) #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
#[CNode]804
    %9 = Primitive::TupleGetItem{prim_type=1}(%7, I64(1))    #(Undefined, I64NoShape) #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
#[CNode]805
    %10 = FuncGraph::fg_806(%8, %9)    #(Undefined, Undefined)    # fg_806=↓Conv2D.806 #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
#[CNode]807
    %11 = TupleAdd::tuple_add(%2, %10)    #(Tuple[EnvType]TupleShape(NoShape), Undefined) #scope: Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d
#808
    Primitive::Return{prim_type=1}(%11)    #(Undefined) #scope: Gradients/Default/network-WithLossCell/_backbone-AdvancedClassificationNet/conv2-SequentialCell/0-Conv2d/gradConv2D
      # In file /home/eren/.local/lib/python3.9/site-packages/mindspore/ops/_grad/grad_nn_ops.py:122/        if is_shape_unknown(x_shape):/#[CNode]809
}
# order:
#   1: @Conv2D.810:[CNode]811{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   2: @Conv2D.810:[CNode]812{[0]: [CNode]811, [1]: фx}
#   3: @◂Conv2D.36:x_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: ▸фx}
#   4: @Conv2D.810:[CNode]813{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   5: @Conv2D.810:[CNode]814{[0]: [CNode]813, [1]: фw}
#   6: @◂Conv2D.36:w_shape{[0]: ValueNode<DoSignaturePrimitive> S-Prim-Shape, [1]: ▸фw}
#   7: @Conv2D.810:[CNode]815{[0]: ValueNode<Primitive> resolve, [1]: ValueNode<NameSpace> CommonOPS: 'Namespace:mindspore._extends.parse.trope', [2]: ValueNode<Symbol> MakeTuple}
#   8: @Conv2D.810:[CNode]816{[0]: [CNode]815, [1]: x_shape}
#   9: @◂Conv2D.36:[CNode]797{[0]: ValueNode<DoSignaturePrimitive> S-Prim-is_shape_unknown, [1]: x_shape}
#  10: @◂Conv2D.36:[CNode]799{[0]: ValueNode<FuncGraph> bool_.798, [1]: [CNode]797}
#  11: @◂Conv2D.36:[CNode]802{[0]: ValueNode<Primitive> Switch, [1]: [CNode]799, [2]: ValueNode<FuncGraph> ✓Conv2D.800, [3]: ValueNode<FuncGraph> ✗Conv2D.801}
#  12: @◂Conv2D.36:[CNode]803{[0]: [CNode]802}
#  13: @◂Conv2D.36:[CNode]807{[0]: ValueNode<FuncGraph> ↓Conv2D.806, [1]: [CNode]804, [2]: [CNode]805}
#  14: @◂Conv2D.36:[CNode]809{[0]: ValueNode<Primitive> Return, [1]: 808}
#  15: @◂Conv2D.36:[CNode]804{[0]: ValueNode<Primitive> TupleGetItem, [1]: [CNode]803, [2]: ValueNode<Int64Imm> 0}
#  16: @◂Conv2D.36:[CNode]805{[0]: ValueNode<Primitive> TupleGetItem, [1]: [CNode]803, [2]: ValueNode<Int64Imm> 1}


#===============================================================================
# num of function graphs in stack: 3/4 (Ignored 1 internal frames).
